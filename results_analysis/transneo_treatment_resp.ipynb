{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Run code here before anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:00:32.596348500Z",
     "start_time": "2024-04-11T20:00:32.411767400Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor': \"w\"}\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:00:32.443705900Z",
     "start_time": "2024-04-11T20:00:32.181167400Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "wd_path = \"/home/dk538/rds/hpc-work/pico/src\"\n",
    "sys.path.append(wd_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster\n",
    "from scipy.stats import pearsonr\n",
    "from utils.data_utils import gene_column_renamer\n",
    "import random\n",
    "import pyreadr\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import urllib.request\n",
    "\n",
    "#from models.clinical import ClinicalLogisticRegression, ClinicalRandomForest, ClinicalSVC\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set()\n",
    "sns.set_theme(\n",
    "    context=\"paper\",\n",
    "    style=\"ticks\",\n",
    "    palette=\"colorblind\",\n",
    "    rc={\n",
    "        \"axes.linewidth\": 1,\n",
    "        \"xtick.major.width\": 1,\n",
    "        \"ytick.major.width\": 1,\n",
    "        \"axes.edgecolor\": \"grey\",\n",
    "        \"xtick.labelcolor\": \"black\",\n",
    "        \"xtick.color\": \"grey\",\n",
    "        \"ytick.labelcolor\": \"black\",\n",
    "        \"ytick.color\": \"grey\",\n",
    "    },\n",
    ")\n",
    "import matplotlib.font_manager as fm\n",
    "import urllib.request\n",
    "import matplotlib\n",
    "\n",
    "# Download the font\n",
    "font_url = \"https://github.com/adobe-fonts/source-sans/blob/release/TTF/SourceSans3-Regular.ttf?raw=True\"\n",
    "font_path = f\"{wd_path}/fonts/SourceSans3-Regular.ttf\"  # Specify where to save the font\n",
    "font_bold_url = \"https://github.com/adobe-fonts/source-sans/blob/release/TTF/SourceSans3-Bold.ttf?raw=True\"\n",
    "font_bold_path = f\"{wd_path}/fonts/SourceSans3-Bold.ttf\"  # Specify where to save the font\n",
    "font_it_url = \"https://github.com/adobe-fonts/source-sans/blob/release/TTF/SourceSans3-It.ttf?raw=True\"\n",
    "font_it_path = f\"{wd_path}/fonts/SourceSans3-It.ttf\"  # Specify where to save the font\n",
    "urllib.request.urlretrieve(font_url, font_path)\n",
    "urllib.request.urlretrieve(font_bold_url, font_bold_path)\n",
    "urllib.request.urlretrieve(font_it_url, font_it_path)\n",
    "\n",
    "# in a terminal, run\n",
    "# cp ~/rds/hpc-work/graphdep/results_analysis/figures/*ttf ~/.local/share/fonts\n",
    "# fc-cache -f -v\n",
    "# rm -fr ~/.cache/matplotlib\n",
    "\n",
    "# Then restart Jupyter kernel\n",
    "\n",
    "fm.findfont(\"Source Sans 3\", rebuild_if_missing=True)\n",
    "#fm.findfont(\"Source Sans 3:style=italic\", rebuild_if_missing=True)\n",
    "\n",
    "# Set font globally for Matplotlib\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set_theme(\n",
    "    context=\"paper\",\n",
    "    style=\"ticks\",\n",
    "    palette=\"colorblind\",\n",
    "    rc={\n",
    "        \"axes.linewidth\": 1,\n",
    "        \"xtick.major.width\": 1,\n",
    "        \"ytick.major.width\": 1,\n",
    "        \"axes.edgecolor\": \"grey\",\n",
    "        \"xtick.labelcolor\": \"black\",\n",
    "        \"xtick.color\": \"grey\",\n",
    "        \"ytick.labelcolor\": \"black\",\n",
    "        \"ytick.color\": \"grey\",\n",
    "    },\n",
    ")\n",
    "\n",
    "rc(\"font\", **{\"family\": \"sans-serif\", \"sans-serif\": [\"Source Sans 3\"]})\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"custom\"\n",
    "plt.rcParams[\"mathtext.it\"] = \"Source Sans 3:italic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4 External validation using TransNEO + PBCP (Sammut et al. 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{wd_path}/data/transneo\"\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "## DATA DOWNLOAD\n",
    "if not os.path.exists(f\"{data_path}/transneo-diagnosis-RNAseq-rawcounts.tsv.gz\"):\n",
    "    urllib.request.urlretrieve(\"https://github.com/cclab-brca/neoadjuvant-therapy-response-predictor/raw/refs/heads/master/data/transneo-diagnosis-RNAseq-rawcounts.tsv.gz\", f\"{data_path}/transneo-diagnosis-RNAseq-rawcounts.tsv.gz\")\n",
    "if not os.path.exists(f\"{data_path}/transneo-diagnosis-RNAseq-validTPM.Rdata\"):\n",
    "    urllib.request.urlretrieve(\"https://github.com/cclab-brca/neoadjuvant-therapy-response-predictor/raw/refs/heads/master/data/transneo-diagnosis-RNAseq-validTPM.Rdata\", f\"{data_path}/transneo-diagnosis-RNAseq-validTPM.Rdata\")\n",
    "if not os.path.exists(f\"{data_path}/testing_her2pos_df.csv\"):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/micrisor/NAT-ML/refs/heads/main/inputs/testing_her2pos_df.csv\", f\"{data_path}/testing_her2pos_df.csv\")\n",
    "if not os.path.exists(f\"{data_path}/testing_her2neg_df.csv\"):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/micrisor/NAT-ML/refs/heads/main/inputs/testing_her2neg_df.csv\", f\"{data_path}/testing_her2neg_df.csv\")\n",
    "if not os.path.exists(f\"{data_path}/training_df.csv\"):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/micrisor/NAT-ML/refs/heads/main/inputs/training_df.csv\", f\"{data_path}/training_df.csv\")\n",
    "#ENSEMBL ID to HGNC map and gene lengths (provided in github repo)\n",
    "if not os.path.exists(f\"{data_path}/gene_lengths.txt\"):\n",
    "    raise ValueError(\"gene_lengths.txt not present. Please download from PiCo github repo.\")\n",
    "## DATA LOADING\n",
    "# resp_df = pd.read_excel(\n",
    "#     f\"{data_path}/Supplementary Tables.xlsx\", sheet_name=\"Supplementary Table 1\"\n",
    "# ).set_index(\"Donor.ID\")\n",
    "# resp_df_val = pd.read_excel(\n",
    "#     f\"{data_path}/Supplementary Tables.xlsx\", sheet_name=\"Supplementary Table 4\"\n",
    "# ).set_index(\"Donor.ID\")\n",
    "\n",
    "# Combine training and validation data\n",
    "feat_df = (\n",
    "    pd.read_csv(f\"{data_path}/training_df.csv\")\n",
    "    .drop(\"Unnamed: 0\", axis=1)\n",
    "    .set_index(\"Trial.ID\")\n",
    ")\n",
    "feat_df_val_1 = (\n",
    "    pd.read_csv(f\"{data_path}/testing_her2neg_df.csv\")\n",
    "    .drop(\"Unnamed: 0\", axis=1)\n",
    "    .set_index(\"Trial.ID\")\n",
    ")\n",
    "feat_df_val_2 = pd.read_csv(f\"{data_path}/testing_her2pos_df.csv\").set_index(\n",
    "    \"Trial.ID\"\n",
    ")\n",
    "feat_df_val = pd.concat([feat_df_val_1, feat_df_val_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.2 RNASeq: Counts to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-11T20:00:34.076256500Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def normalize_expression(X:pd.DataFrame, method:str=\"tpm\", length:pd.Series=None):\n",
    "    \"\"\"\n",
    "    # TPM\n",
    "    Transcripts Per Kilobase Million\n",
    "        (1) Divide the read counts by the length of each gene in kilobases. This gives you reads per kilobase (RPK).\n",
    "        (2) Count up all the RPK values in a sample and divide this number by 1,000,000. This is your “per million” scaling factor.\n",
    "        (3) Divide the RPK values by the “per million” scaling factor. This gives you TPM.\n",
    "\n",
    "    # Notes:\n",
    "    Proper pseudocount addition would be the following as shown by metagenomeSeq's MRcounts\n",
    "    log(X_normalized + 1)\n",
    "    \"\"\"\n",
    "    if method is None:\n",
    "        return X\n",
    "\n",
    "    method = method.lower()\n",
    "\n",
    "\n",
    "    # Lengths\n",
    "    if method in {\"fpkm\", \"rpkm\", \"rpk\",  \"tpm\"}:\n",
    "        assert length is not None, \"If FPKM, RPKM, TPM, or GeTMM is chosed as the method then `length` cannot be None.  It must be either a pd.Series of sequences or sequence lengths\"\n",
    "        length = pd.Series(length)[X.columns]\n",
    "        assert length.isnull().sum() == 0, \"Not all of the genes in `X.columns` are in `length.index`.  Either use a different normalization or get the missing sequence lengths\"\n",
    "        # If sequences are given then convert to length (assumes CDS and no introns)\n",
    "        if pd.api.types.is_string_dtype(length):\n",
    "            length = length.map(len)\n",
    "\n",
    "    # FPKM, RPKM, and TPM normalization\n",
    "    if method in {\"fpkm\", \"rpkm\", \"rpk\", \"tpm\"}:\n",
    "\n",
    "        # Set up variables\n",
    "        C = X.values\n",
    "        L = length.values\n",
    "        N = X.sum(axis=1).values.reshape(-1,1)\n",
    "\n",
    "\n",
    "        if method in {\"fpkm\",\"rpkm\"}:\n",
    "            # Compute operations\n",
    "            numerator = 1e9 * C\n",
    "            denominator = (N*L)\n",
    "            return pd.DataFrame(numerator/denominator, index=X.index, columns=X.columns)\n",
    "\n",
    "        if method in {\"rpk\", \"tpm\"}:\n",
    "            rpk = C/L\n",
    "            if method == \"rpk\":\n",
    "                return pd.DataFrame(rpk, index=X.index, columns=X.columns)\n",
    "            if method == \"tpm\":\n",
    "                per_million_scaling_factor = (rpk.sum(axis=1)/1e6).reshape(-1,1)\n",
    "                return pd.DataFrame( rpk/per_million_scaling_factor, index=X.index, columns=X.columns)\n",
    "\n",
    "\n",
    "def counts_to_tpm(counts_df, lengths_df):\n",
    "    gene_int = sorted(list(set(counts_df.columns).intersection(lengths_df[\"gene\"])))\n",
    "    counts_df_filt = counts_df[gene_int]\n",
    "    lengths = lengths_df.set_index(\"gene\").loc[gene_int]\n",
    "    # If multiple canonical transcripts take the longest one\n",
    "    lengths = lengths.groupby(lengths.index).max()[\"length\"]\n",
    "    tpm_df = normalize_expression(counts_df, method=\"tpm\", length=lengths)\n",
    "    return tpm_df\n",
    "\n",
    "\n",
    "# Load RNASeq raw counts -- training data\n",
    "raw_counts = (\n",
    "    pd.read_csv(f\"{data_path}/transneo-diagnosis-RNAseq-rawcounts.tsv.gz\", sep=\"\\t\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .transpose()\n",
    ")\n",
    "\n",
    "\n",
    "lengths = pd.read_csv(f\"{data_path}/gene_lengths.txt\", sep=\"\\t\")\n",
    "\n",
    "# Uncomment if using a BioMART export\n",
    "# The file included is as used in Sammut et al.\n",
    "\n",
    "#lengths = lengths[lengths[\"Ensembl Canonical\"] == 1.0]\n",
    "\n",
    "#gene_int = set(raw_counts.columns).intersection(lengths[\"Gene stable ID\"])\n",
    "#lengths_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"gene\": lengths[\"Gene stable ID\"],\n",
    "#         \"length\": lengths[\"Transcript length (including UTRs and CDS)\"],\n",
    "#     }\n",
    "# )\n",
    "tpm = counts_to_tpm(raw_counts, lengths)\n",
    "log_tpm = np.log2(tpm + 1)\n",
    "exp_df = log_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_df.to_csv(\"../data/transneo_exp_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# np.savetxt(\"./ext_val_sammut/raw_counts_ensg.txt\", raw_counts.columns.astype(str).tolist(), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# lengths[\"HGNC symbol\"].to_csv(\"./ext_val_sammut/train_genes.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Convert genes to HGNC symbol from BioMART export (not used)\n",
    "\n",
    "# exp_df = exp_df.rename(\n",
    "#     columns=dict(zip(lengths[\"Gene stable ID\"], lengths[\"HGNC symbol\"]))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Load RNASeq log2TPM for validation set\n",
    "exp_df_val = pyreadr.read_r(\n",
    "    \"../data/transneo/transneo-diagnosis-RNAseq-validTPM.Rdata\"\n",
    ")[None]\n",
    "# Convert to CCLE format (log2(TPM+1))\n",
    "exp_df_val = np.log2(2**exp_df_val + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# This has gene symbols, so we want to check these and then convert back to ENSG\n",
    "exp_df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T10:22:39.550377100Z",
     "start_time": "2024-04-10T10:22:39.440664600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a file for HGNC multi-symbol checker\n",
    "exp_df_val.reset_index()[\"rownames\"].to_csv(\"../data/transneo/val_genes.txt\", header=None, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to HGNC multi-symbol checker and upload the above file (https://www.genenames.org/tools/multi-symbol-checker/), then load the result\n",
    "hgnc_symbol_check = pd.read_csv(\"../data/transneo/hgnc_symbol_checker.csv\", header=1)\n",
    "# Get mapping of HGNC symbol from BioMART (https://www.ensembl.org/biomart/martview) and load (this uses current approved symbols)\n",
    "# Both files downloaded 16/12/24\n",
    "hgnc_to_ensg = pd.read_csv(\"../data/transneo/biomart_hgnc_to_ensg.csv\")#.set_index(\"HGNC ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgnc_symbol_check_map = {row[\"Input\"]: row[\"Approved symbol\"] for ind, row in hgnc_symbol_check.iterrows()}\n",
    "hgnc_to_ensg_map = {row[\"HGNC symbol\"]: row[\"Gene stable ID\"] for ind, row in hgnc_to_ensg.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map rownames to approved symbols, then map to ENSG, then transpose for rows as samples\n",
    "exp_df_val = exp_df_val.rename(hgnc_symbol_check_map, axis=0)\n",
    "exp_df_val = exp_df_val.rename(hgnc_to_ensg_map, axis=0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_df.transpose().reset_index().groupby(\"Unnamed: 0\").max().transpose().dropna(axis=1, how=\"all\")\n",
    "#exp_df_val.transpose().reset_index().groupby(\"rownames\").max().transpose().dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T10:24:34.356858200Z",
     "start_time": "2024-04-10T10:24:34.254033900Z"
    },
    "collapsed": false
   },
   "source": [
    "### 4.0.3 RNASeq: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intersection of genes in exp and exp_val\n",
    "# Remove duplicate genes by taking mean\n",
    "exp_df_val = (\n",
    "    exp_df_val\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .groupby(\"rownames\")\n",
    "    .mean()\n",
    "    .transpose()\n",
    "    .dropna(axis=1, how=\"all\")\n",
    ")\n",
    "exp_df = (\n",
    "    exp_df\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .groupby(\"Unnamed: 0\")\n",
    "    .mean()\n",
    "    .transpose()\n",
    "    .dropna(axis=1, how=\"all\")\n",
    ")\n",
    "# Get intersection of columns\n",
    "shared_genes = sorted(list(set(exp_df_val.columns).intersection(set(exp_df.columns))))\n",
    "exp_df = exp_df[shared_genes]\n",
    "exp_df_val = exp_df_val[shared_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean impute NAs from exp_df for both (mean across rows)\n",
    "exp_df = exp_df.fillna(exp_df.mean(axis=0))\n",
    "exp_df_val = exp_df_val.fillna(exp_df.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(shared_genes))\n",
    "# np.savetxt(\n",
    "#     fname=\"./ext_val_sammut/sammut_genes.csv\", X=shared_genes, fmt=\"%s\", delimiter=\",\"\n",
    "# )\n",
    "# sammut_genes = pd.read_csv(\"./ext_val_sammut/sammut_genes.csv\", header=None)[0].tolist()\n",
    "# print(len(set(sammut_genes).symmetric_difference(shared_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T11:28:04.582928300Z",
     "start_time": "2024-04-11T11:27:50.931720100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save both to file\n",
    "exp_df.to_csv(\"../data/transneo/transneo_exp_filt.csv\")\n",
    "exp_df_val.to_csv(\"../data/transneo/transneo_exp_filt_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T10:34:31.830072100Z",
     "start_time": "2024-04-11T10:34:31.447667Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv(\"../data/transneo/transneo_exp_filt.csv\").set_index(\"Unnamed: 0\")\n",
    "exp_df_val = pd.read_csv(\"../data/transneo/transneo_exp_filt_val.csv\").set_index(\n",
    "    \"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:19:32.196792500Z",
     "start_time": "2024-03-14T22:19:32.012275900Z"
    },
    "collapsed": false
   },
   "source": [
    "### 4.0.4 RNASeq: Comparison to precomputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE PROVIDED VS RECOMUPUTED EXPRESSION VALUES\n",
    "f, ax = plt.subplots(1, 1)\n",
    "comb_df = pd.merge(feat_df, exp_df, left_index=True, right_index=True)\n",
    "comb_df_val = pd.merge(feat_df_val, exp_df_val, left_index=True, right_index=True)\n",
    "comb_df[\"ENSG00000091831\"] = np.log2(2 ** (comb_df[\"ENSG00000091831\"]) - 1 + 0.001)\n",
    "comb_df[\"ENSG00000141736\"] = np.log2(2 ** comb_df[\"ENSG00000141736\"] - 1 + 0.001)\n",
    "comb_df[\"ENSG00000082175\"] = np.log2(2 ** comb_df[\"ENSG00000082175\"] - 1 + 0.001)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "ax.set_xlim(-5, 15)\n",
    "ax.set_ylim(-5, 15)\n",
    "ax.set_xlabel(\"TPM from counts\")\n",
    "ax.set_ylabel(\"TPM from data\")\n",
    "ax.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)\n",
    "sns.scatterplot(data=comb_df, x=\"ENSG00000091831\", y=\"ESR1.log2.tpm\", ax=ax)\n",
    "sns.scatterplot(data=comb_df, x=\"ENSG00000141736\", y=\"ERBB2.log2.tpm\", ax=ax)\n",
    "sns.scatterplot(data=comb_df, x=\"ENSG00000082175\", y=\"PGR.log2.tpm\", ax=ax)\n",
    "comb_df_val[\"ENSG00000091831\"] = np.log2(2 ** comb_df_val[\"ENSG00000091831\"] - 1)\n",
    "comb_df_val[\"ENSG00000141736\"] = np.log2(2 ** comb_df_val[\"ENSG00000141736\"] - 1)\n",
    "comb_df_val[\"ENSG00000082175\"] = np.log2(2 ** comb_df_val[\"ENSG00000082175\"] - 1)\n",
    "f, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(data=comb_df_val, x=\"ENSG00000091831\", y=\"ESR1.log2.tpm\", ax=ax)\n",
    "sns.scatterplot(data=comb_df_val, x=\"ENSG00000141736\", y=\"ERBB2.log2.tpm\", ax=ax)\n",
    "sns.scatterplot(data=comb_df_val, x=\"ENSG00000082175\", y=\"PGR.log2.tpm\", ax=ax)\n",
    "ax.set_xlim(-5, 15)\n",
    "ax.set_ylim(-5, 15)\n",
    "\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, \"k-\", alpha=0.75, zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T10:28:41.291863Z",
     "start_time": "2024-04-11T10:28:41.055320100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR LOADING DATA\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "\n",
    "def plot_rcb(\n",
    "    rep_df, resp_df, plot_dim, ax, plot_type=\"RCB.category\", treat_str=\"F\", filt=False\n",
    "):\n",
    "    # Combine dataframes\n",
    "    sns.set_theme(context=\"paper\", style=\"whitegrid\", palette=\"Set2\")\n",
    "    plot_df = pd.merge(rep_df, resp_df, left_index=True, right_index=True, how=\"inner\")\n",
    "    plot_df[treat_str] = plot_df[\"NAT.regimen\"].str.contains(treat_str)\n",
    "    if filt:\n",
    "        plot_df = plot_df[plot_df[treat_str]]\n",
    "    if plot_type == \"RCB.category\":\n",
    "        # f, ax = plt.subplots(1, 1, figsize=(2, 2.5))\n",
    "        pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        rcb1_z = plot_df[plot_df[plot_type] == \"RCB-I\"][plot_dim]\n",
    "        rcb2_z = plot_df[plot_df[plot_type] == \"RCB-II\"][plot_dim]\n",
    "        rcb3_z = plot_df[plot_df[plot_type] == \"RCB-III\"][plot_dim]\n",
    "        p_01 = ranksums(pcr_z, rcb1_z).pvalue\n",
    "        p_02 = ranksums(pcr_z, rcb2_z).pvalue\n",
    "        p_03 = ranksums(pcr_z, rcb3_z).pvalue\n",
    "        if filt:\n",
    "            treat_str = plot_type\n",
    "        sns.boxplot(\n",
    "            data=plot_df,\n",
    "            x=plot_type,\n",
    "            y=plot_dim,\n",
    "            hue=treat_str,\n",
    "            order=[\"pCR\", \"RCB-I\", \"RCB-II\", \"RCB-III\"],\n",
    "            width=0.6,\n",
    "            whis=1.5,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.text(0.4, 1, f\"p={p_01:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        ax.text(0.6, 0.95, f\"p={p_02:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        ax.text(0.8, 0.90, f\"p={p_03:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        ax.set_xticks([0, 1, 2, 3], [\"pCR\", \"I\", \"II\", \"III\"])\n",
    "        if filt:\n",
    "            ax.legend([], [], frameon=False)\n",
    "        sns.despine(ax=ax)\n",
    "    elif plot_type == \"pCR.RD\":\n",
    "        # f, ax = plt.subplots(1, 1, figsize=(1, 2.5))\n",
    "        pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        rd_z = plot_df[plot_df[plot_type] == \"RD\"][plot_dim]\n",
    "        p = ranksums(pcr_z, rd_z).pvalue\n",
    "        if filt:\n",
    "            treat_str = plot_type\n",
    "        sns.boxplot(\n",
    "            data=plot_df,\n",
    "            x=plot_type,\n",
    "            y=plot_dim,\n",
    "            hue=treat_str,\n",
    "            order=[\"pCR\", \"RD\"],\n",
    "            width=0.6,\n",
    "            whis=1.5,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.text(0.5, 0.95, f\"p={p:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        if filt:\n",
    "            ax.legend([], [], frameon=False)\n",
    "        else:\n",
    "            ax.legend(title=\"Treatment\", loc=(0.9, 0.7))\n",
    "        sns.despine(ax=ax)\n",
    "    elif plot_type == \"RCB.score\":\n",
    "        # f, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "        # plot_df = plot_df[plot_df[\"RCB.category\"]!=\"pCR\"]\n",
    "        plot_df = plot_df[[plot_dim, plot_type, treat_str]].dropna(axis=0)\n",
    "        z = plot_df[plot_dim]\n",
    "        score = plot_df[plot_type]\n",
    "        r, p = pearsonr(z, score)\n",
    "        sns.scatterplot(data=plot_df, y=plot_type, x=plot_dim, hue=treat_str, ax=ax)\n",
    "        ax.text(0.75, 0.75, f\"p={p:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        if filt:\n",
    "            ax.legend([], [], frameon=False)\n",
    "        else:\n",
    "            ax.legend(title=\"Treatment\", loc=(0.9, 0.7))\n",
    "        sns.despine(ax=ax)\n",
    "    else:\n",
    "        plt.figure(figsize=(1, 2.5))\n",
    "        # pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        # rd_z = plot_df[plot_df[plot_type] == \"RD\"][plot_dim]\n",
    "        # p = ranksums(pcr_z, rd_z).pvalue\n",
    "        sns.boxplot(\n",
    "            data=plot_df,\n",
    "            x=plot_type,\n",
    "            y=plot_dim,\n",
    "            hue=treat_str,\n",
    "            width=0.6,\n",
    "            whis=1.5,\n",
    "            ax=ax,\n",
    "        )\n",
    "        # plt.text(1, max(plot_df[plot_dim]+0.1), f\"p={p:.2g}\", {\"ha\":\"center\"})\n",
    "        if filt:\n",
    "            ax.legend([], [], frameon=False)\n",
    "        sns.despine(ax=ax)\n",
    "    ax.grid(False)\n",
    "\n",
    "\n",
    "def plot_rcb_density(\n",
    "    rep_df, resp_df, plot_dim, plot_type=\"RCB.category\", treat_str=\"F\", filt=False\n",
    "):\n",
    "    # Combine dataframes\n",
    "    sns.set_theme(context=\"paper\", style=\"whitegrid\", palette=\"Set2\")\n",
    "    plot_df = pd.merge(rep_df, resp_df, left_index=True, right_index=True, how=\"inner\")\n",
    "    plot_df[treat_str] = plot_df[\"NAT.regimen\"].str.contains(treat_str)\n",
    "    if filt:\n",
    "        plot_df = plot_df[plot_df[treat_str]]\n",
    "    if plot_type == \"RCB.category\":\n",
    "        f, ax = plt.subplots(1, 1, figsize=(3, 2.5))\n",
    "        pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        rcb1_z = plot_df[plot_df[plot_type] == \"RCB-I\"][plot_dim]\n",
    "        rcb2_z = plot_df[plot_df[plot_type] == \"RCB-II\"][plot_dim]\n",
    "        rcb3_z = plot_df[plot_df[plot_type] == \"RCB-III\"][plot_dim]\n",
    "        p_01 = ranksums(pcr_z, rcb1_z).pvalue\n",
    "        p_02 = ranksums(pcr_z, rcb2_z).pvalue\n",
    "        p_03 = ranksums(pcr_z, rcb3_z).pvalue\n",
    "        if filt:\n",
    "            treat_str = plot_type\n",
    "        sns.kdeplot(\n",
    "            data=plot_df,\n",
    "            x=plot_dim,\n",
    "            hue=plot_type,\n",
    "            hue_order=[\"pCR\", \"RCB-I\", \"RCB-II\", \"RCB-III\"],\n",
    "            common_norm=False,\n",
    "        )\n",
    "        plt.text(0.4, 1, f\"p={p_01:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        plt.text(0.6, 0.95, f\"p={p_02:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        plt.text(0.8, 0.90, f\"p={p_03:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        sns.despine(ax=ax)\n",
    "    elif plot_type == \"pCR.RD\":\n",
    "        f, ax = plt.subplots(1, 1, figsize=(3, 2.5))\n",
    "        pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        rd_z = plot_df[plot_df[plot_type] == \"RD\"][plot_dim]\n",
    "        p = ranksums(pcr_z, rd_z).pvalue\n",
    "        if filt:\n",
    "            treat_str = plot_type\n",
    "        sns.kdeplot(\n",
    "            data=plot_df,\n",
    "            x=plot_dim,\n",
    "            hue=plot_type,\n",
    "            hue_order=[\"pCR\", \"RD\"],\n",
    "            common_norm=False,\n",
    "        )\n",
    "        plt.text(\n",
    "            0.15, 0.9, f\"Wilcoxon\\np={p:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes\n",
    "        )\n",
    "        plt.title(plot_dim)\n",
    "        sns.despine()\n",
    "    elif plot_type == \"RCB.score\":\n",
    "        f, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "        # plot_df = plot_df[plot_df[\"RCB.category\"]!=\"pCR\"]\n",
    "        plot_df = plot_df[[plot_dim, plot_type, treat_str]].dropna(axis=0)\n",
    "        z = plot_df[plot_dim]\n",
    "        score = plot_df[plot_type]\n",
    "        r, p = pearsonr(z, score)\n",
    "        sns.scatterplot(data=plot_df, y=plot_type, x=plot_dim, hue=treat_str)\n",
    "        plt.text(0.75, 0.75, f\"p={p:.2g}\", {\"ha\": \"center\"}, transform=ax.transAxes)\n",
    "        sns.despine()\n",
    "    else:\n",
    "        plt.figure(figsize=(1, 2.5))\n",
    "        # pcr_z = plot_df[plot_df[plot_type] == \"pCR\"][plot_dim]\n",
    "        # rd_z = plot_df[plot_df[plot_type] == \"RD\"][plot_dim]\n",
    "        # p = ranksums(pcr_z, rd_z).pvalue\n",
    "        sns.boxplot(\n",
    "            data=plot_df, x=plot_type, y=plot_dim, hue=treat_str, width=0.6, whis=1.5\n",
    "        )\n",
    "        # plt.text(1, max(plot_df[plot_dim]+0.1), f\"p={p:.2g}\", {\"ha\":\"center\"})\n",
    "        sns.despine()\n",
    "    ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T10:28:56.808589600Z",
     "start_time": "2024-04-11T10:28:47.944644500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_rcb(rep_df_plot, resp_df, \"z_TSPAN32\", ax, plot_type=\"pCR.RD\", filt=True)\n",
    "nrows = 4\n",
    "rep_dict_plot = rep_dict[\"PiCo_E\"].loc[\n",
    "    :, rep_dict[\"PiCo_E\"].columns.str.startswith(\"z\")\n",
    "]\n",
    "fig, axes = plt.subplots(\n",
    "    nrows,\n",
    "    int(np.ceil(len(rep_dict_plot.columns) / nrows)),\n",
    "    figsize=(12, 8),\n",
    "    sharex=True,\n",
    ")\n",
    "for i, col in enumerate(rep_dict_plot.columns):\n",
    "    y = i // nrows\n",
    "    x = i % nrows\n",
    "    plot_rcb(rep_dict_plot, resp_df, col, axes[x, y], plot_type=\"pCR.RD\", filt=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T10:28:58.525581300Z",
     "start_time": "2024-04-11T10:28:56.787248400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in rep_dict[\"PICo\"].columns:\n",
    "    if col.startswith(\"z\"):\n",
    "        plot_rcb_density(rep_dict[\"PICo\"], resp_df, col, plot_type=\"pCR.RD\", filt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-11T10:28:58.501729700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_rcb_grid(rep_df, resp_df, dims, filt=True, treat_str=\"F\"):\n",
    "    sns.set_theme(context=\"paper\", style=\"whitegrid\", palette=\"Set2\")\n",
    "    plot_df = pd.merge(rep_df, resp_df, left_index=True, right_index=True, how=\"inner\")\n",
    "    rcb_cats = [\"pCR\", \"RCB-I\", \"RCB-II\", \"RCB-III\"]\n",
    "    plot_df[treat_str] = plot_df[\"Chemo.Regimen\"].str.contains(treat_str)\n",
    "    if filt:\n",
    "        plot_df = plot_df[plot_df[treat_str]]\n",
    "    min_0 = min(plot_df[dims[0]])\n",
    "    max_0 = max(plot_df[dims[0]])\n",
    "    min_1 = min(plot_df[dims[1]])\n",
    "    max_1 = max(plot_df[dims[1]])\n",
    "    range_0 = max_0 - min_0\n",
    "    range_1 = max_1 - min_1\n",
    "    fig, ax = plt.subplots(1, 4, sharex=True, sharey=True, **{\"figsize\": (8, 2)})\n",
    "    for i, cat in enumerate(rcb_cats):\n",
    "        plot_z = plot_df[plot_df[\"RCB.category\"] == cat][dims]\n",
    "        sns.kdeplot(data=plot_z, x=dims[0], y=dims[1], ax=ax[i])\n",
    "        ax[i].set_title(cat)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-11T10:28:58.501729700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_rcb_grid(rep_dict[\"PiCo\"], resp_df, [\"z_HNF1B\", \"z_KANK4\"], filt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-15T01:37:29.422315400Z",
     "start_time": "2024-03-15T01:37:29.298925300Z"
    },
    "collapsed": false
   },
   "source": [
    "### 4.0.5 Constraint selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import Manual, get_data_loaders, get_constraints, gene_column_renamer, process_data\n",
    "# Getting constraints related to each drug in FEC-T\n",
    "# SELECTING CONSTRAINTS\n",
    "# Consensus of both datasets -- get constraints for GDSC and CTRP\n",
    "\n",
    "drugs_gdsc = [\"5-FLUOROURACIL\", \"EPIRUBICIN\", \"CYCLOPHOSPHAMIDE\", \"PACLITAXEL\"]\n",
    "drugs_ctrp = [\"FLUOROURACIL\", \"DOXORUBICIN\", \"CYCLOPHOSPHAMIDE\", \"PACLITAXEL\"]\n",
    "dataset_names = [\"depmap_gdsc\", \"depmap_ctrp\"]\n",
    "\n",
    "constraints_dict = {}\n",
    "\n",
    "for drug in drugs_gdsc:\n",
    "    constraints = get_constraints(\n",
    "    drug=drug,\n",
    "    dataset_name=\"depmap_gdsc\",\n",
    "    zdim=512,\n",
    "    experiment=None,\n",
    "    col_thresh=1.0,\n",
    "    wd_path=wd_path,\n",
    "    )\n",
    "    constraints_dict[f\"{drug}_gdsc\"] = constraints\n",
    "\n",
    "for drug in drugs_ctrp:\n",
    "    constraints = get_constraints(\n",
    "    drug=drug,\n",
    "    dataset_name=\"depmap_ctrp\",\n",
    "    zdim=512,\n",
    "    experiment=None,\n",
    "    col_thresh=1.0,\n",
    "    wd_path=wd_path,\n",
    "    )\n",
    "    constraints_dict[f\"{drug}_ctrp\"] = constraints\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the constraint dfs\n",
    "constraint_dfs = []\n",
    "for drug in drugs_gdsc:\n",
    "    curr_df = pd.read_csv(f\"{wd_path}/data/constraints/univar_lm_{drug}_lrt_IC50_depmap_gdsc_v2.csv\")\n",
    "    curr_df[\"drug\"] = drug\n",
    "    curr_df[\"dataset_name\"] = \"depmap_gdsc\"\n",
    "    constraint_dfs.append(curr_df)\n",
    "\n",
    "for drug in drugs_ctrp:\n",
    "    curr_df = pd.read_csv(f\"{wd_path}/data/constraints/univar_lm_{drug}_lrt_IC50_depmap_ctrp_v2.csv\")\n",
    "    curr_df[\"drug\"] = drug\n",
    "    curr_df[\"dataset_name\"] = \"depmap_ctrp\"\n",
    "    constraint_dfs.append(curr_df)\n",
    "\n",
    "constraint_df = pd.concat(constraint_dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by signifcance after correction\n",
    "constraint_df_filt = constraint_df[constraint_df[\"p_corrected\"] < 0.05]\n",
    "# Count the occurrence of each gene across the datasets and drugs (max 8)\n",
    "constraint_df_filt[\"count\"] = constraint_df_filt.groupby(\"gene\")[\"gene\"].transform(\"count\")\n",
    "# Print these, grouped by count and sorted by corrected p val within each count\n",
    "constraint_df_filt.sort_values([\"dataset_name\", \"drug\", \"p_corrected\"]).groupby([\"dataset_name\", \"drug\"]).head(200000).sort_values(by=[\"count\", \"p_corrected\"], ascending=[False, True]).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxane_metagene = [\"BUB1B\", \"CDADC1\", \"MASTL\", \"CDK1\", \"CSNK1A1L\",\n",
    "                    \"STK4\", \"TTK\", \"EEF2K\", \"SCYL1\", \"AURKB\", \"UGCG\",\n",
    "                      \"GBA1\", \"GBA3\", \"CERT1\"]\n",
    "taxane_metagene_aliases = {\"CDC2\": \"CDK1\", \"COL4A3BP\": \"CERT1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import process_data, Manual\n",
    "# Check data availability \n",
    "dataset_name = \"depmap_gdsc_scanb_tcga\"\n",
    "\n",
    "# PROCESS DATASET\n",
    "x, s, c, y, test_samples = process_data(dataset=dataset_name, wd_path=wd_path, experiment=\"tcga_surv\")\n",
    "\n",
    "dataset_params = {\"var_filt_x\": 1500, \"var_filt_s\": None}\n",
    "\n",
    "dataset = Manual(x=x, s=s, c=c, y=y, constraints=[\"MCL1\", \"PSMC1\", \"FANCF\", \"RAD1\", \"PPM1D\", \"ESR1\", \"ERBB2\", \"CDKN2A\", \"TP53\", \"IGF1R\", \"FGFR2\", \"CCNE1\", \"PIK3CA\", \"GATA3\", \"MAP3K1\", \"EGFR\"], target=\"BCFi_MONTHS\", params=dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Prediction performance on TransNEO & ARTemis+PBCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"resp.pCR\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "rep_types = {\"vae\": \"VAE\", \"icovae_MCL1_16\": \"PiCo\"}\n",
    "#model_types = [\"ElasticNet\", \"SVR\", \"RandomForestRegressor\"]\n",
    "model_types = [\"LogisticRegression\"]\n",
    "feat_sets = {\"RNA\": \"_PGR.log2.tpm_11_norep\", \"Rep\": \"\", \"Clinical+Rep\": \"_Size.at.diagnosis_7\", \"Clinical+Rep+RNA\": \"_Size.at.diagnosis_18\", \"Clinical+RNA\": \"_Size.at.diagnosis_18_norep\", \"Clinical\": \"_Size.at.diagnosis_7_norep\"}\n",
    "feat_sets_conf = {\"Rep\": [],\n",
    "     \"Clinical+Rep\": [\"Size.at.diagnosis\", \"LN.at.diagnosis\", \"Age.at.diagnosis\", \"Histology\", \"ER.status\", \"HER2.status\", \"Grade.pre.chemotherapy\"],\n",
    "     \"Clinical\": [\"Size.at.diagnosis\", \"LN.at.diagnosis\", \"Age.at.diagnosis\", \"Histology\", \"ER.status\", \"HER2.status\", \"Grade.pre.chemotherapy\"],\n",
    "     \"Clinical+Rep+RNA\": [\"Size.at.diagnosis\", \"LN.at.diagnosis\", \"Age.at.diagnosis\", \"Histology\", \"ER.status\", \"HER2.status\", \"Grade.pre.chemotherapy\", \"PGR.log2.tpm\", \"ESR1.log2.tpm\", \"ERBB2.log2.tpm\", \"GGI.ssgsea.notnorm\", \"ESC.ssgsea.notnorm\", \"Swanton.PaclitaxelScore\", \"STAT1.ssgsea.notnorm\", \"TIDE.Dysfunction\", \"TIDE.Exclusion\", \"Danaher.Mast.cells\", \"CytScore.log2\"],\n",
    "     \"Clinical+RNA\": [\"Size.at.diagnosis\", \"LN.at.diagnosis\", \"Age.at.diagnosis\", \"Histology\", \"ER.status\", \"HER2.status\", \"Grade.pre.chemotherapy\", \"PGR.log2.tpm\", \"ESR1.log2.tpm\", \"ERBB2.log2.tpm\", \"GGI.ssgsea.notnorm\", \"ESC.ssgsea.notnorm\", \"Swanton.PaclitaxelScore\", \"STAT1.ssgsea.notnorm\", \"TIDE.Dysfunction\", \"TIDE.Exclusion\", \"Danaher.Mast.cells\", \"CytScore.log2\"],\n",
    "     \"RNA\": [\"PGR.log2.tpm\", \"ESR1.log2.tpm\", \"ERBB2.log2.tpm\", \"GGI.ssgsea.notnorm\", \"ESC.ssgsea.notnorm\", \"Swanton.PaclitaxelScore\", \"STAT1.ssgsea.notnorm\", \"TIDE.Dysfunction\", \"TIDE.Exclusion\", \"Danaher.Mast.cells\", \"CytScore.log2\"]}\n",
    "\n",
    "# Mapping for feature names in plots\n",
    "names_map = {\n",
    "    \"Danaher.Mast.cells\": \"Mast cell score\",\n",
    "    \"PGR.log2.tpm\": \"$\\t{{PGR}}$ expression\",\n",
    "    \"ESR1.log2.tpm\": \"$\\t{{ESR1}}$ expression\",\n",
    "    \"ERBB2.log2.tpm\": \"$\\t{{ERBB2}}$ expression\",\n",
    "    \"HER2.status\": \"HER2 status\",\n",
    "    \"Age.at.diagnosis\": \"Age at diagnosis\",\n",
    "    \"LN.at.diagnosis\": \"LN involvement\",\n",
    "    \"Grade.pre.chemotherapy\": \"Histological grade\",\n",
    "    \"TIDE.Exclusion\": \"T cell exclusion\",\n",
    "    \"TIDE.Dysfunction\": \"T cell dysfunction\",\n",
    "    \"Size.at.diagnosis\": \"Tumour size\",\n",
    "    \"GGI.ssgsea.notnorm\": \"GGI score\",\n",
    "    \"ESC.ssgsea.notnorm\": \"ES cell score\",\n",
    "    \"Swanton.PaclitaxelScore\": \"Taxane score\",\n",
    "    \"CytScore.log2\": \"Cytolytic score\",\n",
    "    \"STAT1.ssgsea.notnorm\": \"STAT1 score\",\n",
    "    \"Histology\": \"Histological subtype\",\n",
    "    \"ER.status\": \"ER status\",\n",
    "    \"HRD.sum\": \"HRD score\",\n",
    "    \"CodingMuts.PIK3CA\": \"$PIK3CA$ mutation status\",\n",
    "    \"CodingMuts.TP53\": \"$TP53$ mutation status\",\n",
    "    \"CIN.Prop\": \"Chromosomal instability\",\n",
    "    \"All.TMB\": \"All TMB\",\n",
    "    \"Coding.TMB\": \"Coding TMB\",\n",
    "    \"Expressed.NAg\": \"Neoantigens\",\n",
    "    \"HLA.LOH\": \"HLA LOH\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Performance overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TEST SET RESULTS\n",
    "from utils.comp_utils import calculate_feat_imps, plot_feat_imps\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, auc\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "seeds = [10,20,30,40,50,60,70,80,90,100]\n",
    "hopt_seed = 4563\n",
    "\n",
    "test_metrics_df = None\n",
    "val_metrics_list = []\n",
    "hopt_df = None\n",
    "\n",
    "\n",
    "for feat_set, ext in feat_sets.items():\n",
    "    for rep_type, rep_type_label in rep_types.items():\n",
    "        for model_type in model_types:\n",
    "            print(f\"Processing {model_type}, {rep_type}, {ext}...\")\n",
    "            if (rep_type_label == \"PiCo\") and (feat_set in [\"Clinical+Rep+RNA\"]) and (model_type in [\"ElasticNet\", \"LogisticRegression\"]):\n",
    "                try:\n",
    "                    pred_dict_list, constraints, confounders, feat_imps_df = calculate_feat_imps(enc=rep_type, reg=model_type, model_path=f\"{res_root}/{model_type}_{rep_type + ext}\", target=target, seeds=seeds)\n",
    "                    if feat_set in [\"Clinical\", \"Clinical+RNA\", \"RNA\"]:\n",
    "                        zdim = 0\n",
    "                        norep = True\n",
    "                    else:\n",
    "                        zdim = 64\n",
    "                        norep = False\n",
    "\n",
    "                    if (target == \"RCB.score\"):\n",
    "                        plot_feat_imps(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_r_{rep_type+ext}\", metric=\"r\", norep=norep, sort_feats=True, top_k=16)\n",
    "                        plot_feat_imps(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_s_{rep_type+ext}\", metric=\"s\", norep=norep, sort_feats=True, top_k=16)\n",
    "                        plot_feat_imps(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_rmse_{rep_type+ext}\", metric=\"rmse\", norep=norep, sort_feats=True, top_k=16)\n",
    "                    else:\n",
    "                        plot_feat_imps(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_auroc_{rep_type+ext}\", metric=\"auroc\", norep=norep, sort_feats=True, top_k=16)\n",
    "                except:\n",
    "                    print(f\"Cannot produce feat imp plot for {model_type}, {rep_type}, {ext}...\")\n",
    "            try:\n",
    "                print(\"Loading hopt results...\")\n",
    "                #best_trial = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/opt_study_results_s{hopt_seed}.csv\").sort_values(\"value\", ascending=False)[\"number\"][0]\n",
    "                curr_hopt_df = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/cv_results_best_s{hopt_seed}.csv\")\n",
    "\n",
    "                preds_val =  None\n",
    "\n",
    "                print(\"Loading validation predictions...\")\n",
    "                for fold in range(5):\n",
    "                    curr_preds_val = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/z_pred_val_{fold}_best_s{hopt_seed}.csv\")\n",
    "                    if preds_val is None:\n",
    "                        preds_val = curr_preds_val\n",
    "                    else:\n",
    "                        preds_val = pd.concat([preds_val, curr_preds_val], axis=0)\n",
    "\n",
    "                print(\"Calculating validation metrics...\")\n",
    "                pred_metrics_val = preds_val[[\"pred_0\", \"y\"]].dropna()\n",
    "                pred_metrics_auroc_val = pred_metrics_val.copy()\n",
    "                pred_metrics_auroc_val[\"y\"] = (pred_metrics_auroc_val[\"y\"] == 0.0).astype(float)\n",
    "                auc_val = roc_auc_score(pred_metrics_auroc_val[\"y\"], pred_metrics_auroc_val[\"pred_0\"])\n",
    "                auc_neg_val = roc_auc_score(pred_metrics_auroc_val[\"y\"], -1*pred_metrics_auroc_val[\"pred_0\"])\n",
    "                auc_val = np.max([auc_val, auc_neg_val])\n",
    "                f1_val = f1_score(pred_metrics_auroc_val[\"y\"], (pred_metrics_auroc_val[\"pred_0\"]>0.5).astype(float))\n",
    "                precision, recall, thresholds = precision_recall_curve(\n",
    "                    pred_metrics_auroc_val[\"y\"], pred_metrics_auroc_val[\"pred_0\"], pos_label=1\n",
    "                    )\n",
    "                val_aupr = auc(recall, precision)\n",
    "                # Store CV results as well\n",
    "                print(\"Storing validation metrics...\")\n",
    "                if target == \"RCB.score\":\n",
    "                    val_metrics_list.append({\"n\": len(pred_metrics_val), \"rep_type\": rep_type_label, \"model_type\": model_type, \"feat_sets\": feat_set, \"seed\": hopt_seed,\n",
    "                                            \"val_spearmanr\": spearmanr(pred_metrics_val[\"pred_0\"], pred_metrics_val[\"y\"])[0], \"val_pearsonr\": pearsonr(pred_metrics_val[\"pred_0\"], pred_metrics_val[\"y\"])[0],\n",
    "                                                \"val_rmse\": (np.sqrt(pred_metrics_val[\"pred_0\"] - pred_metrics_val[\"y\"])**2).mean(), \"dataset\": \"cv\"})\n",
    "                elif target == \"resp.pCR\":\n",
    "                    val_metrics_list.append({\"n\": len(pred_metrics_val), \"rep_type\": rep_type_label, \"model_type\": model_type, \"feat_sets\": feat_set, \"seed\": hopt_seed,\n",
    "                                                \"val_auroc\": auc_val, \"val_aupr\": val_aupr, \"val_f1\": f1_val, \"dataset\": \"cv\"})\n",
    "                \n",
    "                curr_test_metrics_df = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/test_metrics.csv\")\n",
    "                curr_test_metrics_df[\"rep_type\"] = rep_type_label\n",
    "                curr_test_metrics_df[\"model_type\"] = model_type\n",
    "                curr_hopt_df[\"rep_type\"] = rep_type_label\n",
    "                curr_hopt_df[\"model_type\"] = model_type\n",
    "                # Placeholder until we add clinical features etc\n",
    "                curr_test_metrics_df[\"feat_sets\"] = feat_set\n",
    "                curr_hopt_df[\"feat_sets\"] = feat_set\n",
    "                curr_hopt_df[\"seed\"] = 4563\n",
    "                curr_test_metrics_df[\"seed\"] = seeds\n",
    "                print(\"Combining test metrics...\")\n",
    "                if test_metrics_df is None:\n",
    "                    test_metrics_df = curr_test_metrics_df\n",
    "                else:\n",
    "                    test_metrics_df = pd.concat([test_metrics_df, curr_test_metrics_df], axis=0)\n",
    "                print(\"Combining hopt results...\")\n",
    "                if hopt_df is None:\n",
    "                    hopt_df = curr_hopt_df\n",
    "                else:\n",
    "                    hopt_df = pd.concat([hopt_df, curr_hopt_df], axis=0)\n",
    "            except:\n",
    "                print(f\"{model_type}, {rep_type}, {ext}, {hopt_seed} not found\")\n",
    "                continue\n",
    "\n",
    "print(\"Done loading...\")\n",
    "\n",
    "test_metrics_df[\"dataset\"] = \"test\"\n",
    "hopt_df[\"dataset\"] = \"cv\"\n",
    "val_metrics_df = pd.DataFrame(val_metrics_list)\n",
    "\n",
    "# Keep all folds for hopt_df\n",
    "\n",
    "# Print results on external validation for reporting\n",
    "test_metrics_df.groupby([\"rep_type\", \"model_type\", \"feat_sets\", \"dataset\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imps_plot = feat_imps_df.copy()\n",
    "if target == \"RCB.score\":\n",
    "    feat_imps_plot[\"fi_s\"] = 100 * (feat_imps_plot[\"s\"] - feat_imps_plot[\"s_perm\"]) / feat_imps_plot[\"s\"]\n",
    "elif target == \"resp.pCR\":\n",
    "    feat_imps_plot[\"fi_auroc\"] = feat_imps_plot[\"auroc\"] - feat_imps_plot[\"auroc_perm\"]\n",
    "feat_imps_plot.groupby([\"dim\"]).mean().sort_values(\"fi_auroc\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CV results\n",
    "val_metrics_df.sort_values(by=\"val_spearmanr\", ascending=False)  # .groupby([\"rep_type\", \"model_type\", \"feat_sets\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED TRAIN AND EXT VAL PERFORMANCE -- DATASET FACET\n",
    "# AUROC\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "target = \"resp.pCR\"\n",
    "\n",
    "metrics_dict = {\"resp.pCR\": [\"auroc\", \"aupr\", \"f1\"], \"RCB.score\": [\"spearmanr\", \"pearsonr\", \"rmse\"]}\n",
    "models_dict = {\"resp.pCR\": [\"LogisticRegression\"], \"RCB.score\": [\"ElasticNet\", \"SVR\", \"RandomForestRegressor\"]}\n",
    "\n",
    "for metric in metrics_dict[target]:\n",
    "    for model in models_dict[target]:\n",
    "\n",
    "        metric_hopt = f\"val_{metric}\"\n",
    "        metric_test = f\"test_{metric}\"\n",
    "\n",
    "        palette = sns.color_palette(\"colorblind\")\n",
    "        # palette = {\"PiCo_D\": pal[1], \"VAE\": pal[0],}\n",
    "        pal_0_desat = sns.set_hls_values(palette[0], l=0.6, s=0.5)\n",
    "        pal_1_desat = sns.set_hls_values(palette[1], l=0.6, s=0.5)\n",
    "        pal_cv = {\n",
    "            \"VAE\": palette[1],\n",
    "            \"PiCo\": palette[0],\n",
    "            \"NA\": \"grey\",\n",
    "        }\n",
    "        pal_ev = {\n",
    "            \"VAE\": palette[1],\n",
    "            \"PiCo\": palette[0],\n",
    "            \"NA\": \"grey\",\n",
    "        }\n",
    "\n",
    "        plot_order = [\"Clinical\", \"RNA\", \"Clinical+RNA\", \"Rep\", \"Clinical+Rep\", \"Clinical+Rep+RNA\"]\n",
    "\n",
    "        facet_order = [\"TransNEO\\nCross-validation\", \"ARTemis+PBCP\\nExternal validation\"]\n",
    "\n",
    "        hopt_df_plot = val_metrics_df[val_metrics_df[\"model_type\"] == model].copy()\n",
    "\n",
    "        hopt_df_plot[\"rep_type_hue\"] = hopt_df_plot[\"rep_type\"].copy()\n",
    "        hopt_df_plot.loc[\n",
    "            hopt_df_plot[\"feat_sets\"].isin([\"Clinical+RNA\", \"Clinical\", \"RNA\"]),\n",
    "            \"rep_type_hue\",\n",
    "        ] = \"NA\"\n",
    "\n",
    "        fig, ax = plt.subplots(1,2, figsize=(4.5,2.5))\n",
    "\n",
    "        ## PLOTS CV RESULTS\n",
    "        if target == \"RCB.score\":\n",
    "            g1 = sns.pointplot(\n",
    "                data=hopt_df_plot,\n",
    "                y=\"feat_sets\",\n",
    "                x=metric_hopt,\n",
    "                hue=\"rep_type_hue\",\n",
    "                order=plot_order,\n",
    "                palette=pal_cv,\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "                errorbar=(\"sd\", 1),\n",
    "                capsize=0.25,\n",
    "                marker=\"o\",\n",
    "                err_kws={\"linewidth\": 1.5, \"alpha\": 0.25},\n",
    "                #legend=False,\n",
    "                ax=ax[0],\n",
    "            )\n",
    "            # , errorbar=(\"ci\", 95), capsize=0.1, err_kws={\"linewidth\": 1, \"alpha\": 0.5})\n",
    "        else:\n",
    "            g1 = sns.pointplot(\n",
    "                data=hopt_df_plot,\n",
    "                y=\"feat_sets\",\n",
    "                x=metric_hopt,\n",
    "                hue=\"rep_type_hue\",\n",
    "                order=plot_order,\n",
    "                palette=pal_cv,\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "                errorbar=(\"sd\", 1),\n",
    "                capsize=0.25,\n",
    "                marker=\"o\",\n",
    "                err_kws={\"linewidth\": 1.5, \"alpha\": 0.25},\n",
    "                #legend=False,\n",
    "                ax=ax[0],\n",
    "            )  # , errorbar=(\"ci\", 95), capsize=0.1, err_kws={\"linewidth\": 1, \"alpha\": 0.5})\n",
    "\n",
    "\n",
    "        ## PLOTS EXT VAL RESULTS\n",
    "        metrics_df_plot = test_metrics_df[test_metrics_df[\"model_type\"] == model].copy(deep=True)\n",
    "        metrics_df_plot[\"rep_type_hue\"] = metrics_df_plot[\"rep_type\"].copy()\n",
    "        metrics_df_plot.loc[\n",
    "            metrics_df_plot[\"feat_sets\"].isin([\"Clinical+RNA\", \"Clinical\", \"RNA\"]), \"rep_type_hue\"\n",
    "        ] = \"NA\"\n",
    "\n",
    "        if target == \"RCB.score\":\n",
    "            sns.pointplot(\n",
    "                data=metrics_df_plot,\n",
    "                y=\"feat_sets\",\n",
    "                x=metric_test,\n",
    "                hue=\"rep_type_hue\",\n",
    "                order=plot_order,\n",
    "                palette=pal_ev,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "                marker=\"o\",\n",
    "                errorbar=(\"sd\", 1),\n",
    "                capsize=0.25,\n",
    "                err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "                ax=ax[1],\n",
    "                legend=False,\n",
    "            )\n",
    "        else:\n",
    "            sns.pointplot(\n",
    "                data=metrics_df_plot,\n",
    "                y=\"feat_sets\",\n",
    "                x=metric_test,\n",
    "                hue=\"rep_type_hue\",\n",
    "                palette=pal_ev,\n",
    "                order=plot_order,\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "                marker=\"o\",\n",
    "                errorbar=(\"sd\", 1),\n",
    "                capsize=0.25,\n",
    "                err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "                ax=ax[1],\n",
    "                legend=False,\n",
    "            )\n",
    "\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "        line_train = Line2D(\n",
    "            [0], [0], label=\"VAE\", color=palette[1], linestyle=\"-\", linewidth=1\n",
    "        )\n",
    "        line_val = Line2D(\n",
    "            [0], [0], label=\"PiCo\", color=palette[0], linestyle=\"-\", linewidth=1\n",
    "        )\n",
    "\n",
    "        leg1 = ax[0].legend(\n",
    "            handles=handles[3:],\n",
    "            bbox_to_anchor=(1.0, 1.6),\n",
    "            loc=\"upper center\",\n",
    "            frameon=False,\n",
    "            ncol=3,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "        leg2 = ax[0].legend(\n",
    "            handles=[line_train, line_val],\n",
    "            bbox_to_anchor=(-0.35, 1.45),\n",
    "            loc=\"upper center\",\n",
    "            frameon=False,\n",
    "            ncol=1,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "        ax[0].add_artist(leg1)\n",
    "        ax[0].add_artist(leg2)\n",
    "\n",
    "        # Rename y ticks\n",
    "        names_dict = {\"Clinical\": \"Clinical\", \"RNA\": fr\"RNA\", \"Clinical+RNA\": \"Clinical+RNA\", \"Rep\": fr\"$\\mathbf{{z}}$\", \"Clinical+Rep\": rf\"Clinical+$\\mathbf{{z}}$\", \"Clinical+Rep+RNA\": rf\"Clinical+$\\mathbf{{z}}$+RNA\"}\n",
    "        #ax.set_yticks(names_dict.keys())\n",
    "        ax[0].set_yticklabels(names_dict.values())\n",
    "\n",
    "        #sns.move_legend(ax, \"upper center\", bbox_to_anchor=(.5, -.2), ncol=1, title=None, frameon=False)\n",
    "        sns.despine()\n",
    "        for i, ax in enumerate(ax):\n",
    "            ax.set_ylabel(\"\")\n",
    "            if target == \"RCB.score\":\n",
    "                if metric_test == \"test_spearmanr\":\n",
    "                    ax.set_xlabel(\"Spearman correlation\", fontsize=10)\n",
    "                    ax.set_xlim(0.5, 0.82)\n",
    "                    ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "                elif metric_test == \"test_pearsonr\":\n",
    "                    ax.set_xlabel(\"Pearson correlation\", fontsize=10)\n",
    "                    ax.set_xlim(0.5, 0.82)\n",
    "                    ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "                elif metric_test == \"test_rmse\":\n",
    "                    ax.set_xlabel(\"RMSE\", fontsize=10)\n",
    "                    ax.set_xlim(0.75, 1.15)\n",
    "                    ax.set_xticks([0.8, 0.9, 1.0, 1.1], [0.8,0.9, 1.0, 1.1])\n",
    "            else:\n",
    "                if metric_test == \"test_auroc\":\n",
    "                    ax.set_xlabel(\"AUROC\", fontsize=10)\n",
    "                    ax.set_xlim(0.68, 0.95)\n",
    "                    ax.set_xticks([0.7, 0.8, 0.9], [0.7, 0.8, 0.9])\n",
    "                elif metric_test == \"test_aupr\":\n",
    "                    ax.set_xlabel(\"AUPR\", fontsize=10)\n",
    "                    ax.set_xlim(0.45, 0.85)\n",
    "                    ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "                elif metric_test == \"test_f1\":\n",
    "                    ax.set_xlabel(\"F1 score\", fontsize=10)\n",
    "                    ax.set_xlim(0.15, 0.75)\n",
    "                    ax.set_xticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7], [0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "                elif metric_test == \"test_cross_entropy\":\n",
    "                    ax.set_xlabel(\"Cross-entropy\", fontsize=10)\n",
    "                    ax.set_xlim(0.3, 0.6)\n",
    "                    ax.set_xticks([0.3, 0.4, 0.5, 0.6], [0.3, 0.4, 0.5, 0.6])\n",
    "            ax.set_title(\"\")\n",
    "            ax.text(\n",
    "                s=facet_order[i],\n",
    "                x=0.5,\n",
    "                y=1.1,\n",
    "                transform=ax.transAxes,\n",
    "                fontweight=\"regular\",\n",
    "                horizontalalignment=\"center\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "            ax.grid(visible=True, axis=\"x\")\n",
    "            ax.tick_params(labelsize=10)\n",
    "            if i > 0:\n",
    "                sns.despine(left=True, ax=ax)\n",
    "                ax.tick_params(\n",
    "                    top=False,\n",
    "                    bottom=True,\n",
    "                    left=False,\n",
    "                    right=False,\n",
    "                    labelleft=False,\n",
    "                    labelbottom=True,\n",
    "                    labelsize=10,\n",
    "                )\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plt.savefig(\n",
    "            f\"./figures/transneo/perf_facet_{target}_{model}_{metric}.png\",\n",
    "            #bbox_extra_artists=(leg1, leg2),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=600,\n",
    "        )\n",
    "        plt.savefig(\n",
    "            f\"./figures/transneo/perf_facet_{target}_{model}_{metric}.svg\",\n",
    "            #bbox_extra_artists=(leg1, leg2),\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV RESULTS REPORTING FOR PAPER\n",
    "val_metrics_df.groupby([\"feat_sets\", \"rep_type\", \"model_type\"]).mean().sort_values(\n",
    "    by=metric_hopt, ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EV RESULTS REPORTING FOR PAPER\n",
    "test_metrics_df.groupby([\"feat_sets\", \"rep_type\", \"model_type\"]).mean().sort_values(by=metric_test, ascending=metric_test==\"test_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 pCR prediction AUROC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TEST SET RESULTS\n",
    "from utils.comp_utils import calculate_feat_imps, plot_feat_imps_v2\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "seeds = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "test_metrics_list = []\n",
    "roc_curves_list = []\n",
    "hopt_df = None\n",
    "plot_roc = True\n",
    "\n",
    "for feat_set, ext in feat_sets.items():\n",
    "    for rep_type, rep_type_label in rep_types.items():\n",
    "        for model_type in model_types:\n",
    "            # if rep_type_label == \"PiCo\":\n",
    "            #     try:\n",
    "            #         pred_dict_list, constraints, confounders, feat_imps_df = calculate_feat_imps(enc=rep_type, reg=model_type, model_path=f\"{res_root}/{model_type}_{rep_type + ext}\", target=target, seeds=seeds)\n",
    "            #         if feat_set in [\"Clinical\", \"Clinical+RNA\", \"RNA\"]:\n",
    "            #             zdim = 0\n",
    "            #             norep = True\n",
    "            #         else:\n",
    "            #             zdim = 64\n",
    "            #             norep = False\n",
    "\n",
    "            #         if target == \"RCB.score\":\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_r_{rep_type+ext}\", metric=\"r\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_s_{rep_type+ext}\", metric=\"s\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_rmse_{rep_type+ext}\", metric=\"rmse\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #         else:\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_auroc_{rep_type+ext}\", metric=\"auroc\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #     except:\n",
    "            #         print(f\"Cannot produce feat imp plot for {model_type}, {rep_type}, {ext}...\")\n",
    "            preds_val =  None\n",
    "            for fold in range(5):\n",
    "                curr_preds_val = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/z_pred_val_{fold}_best_s4563.csv\")\n",
    "                if preds_val is None:\n",
    "                    preds_val = curr_preds_val\n",
    "                else:\n",
    "                    preds_val = pd.concat([preds_val, curr_preds_val], axis=0)\n",
    "\n",
    "            pred_metrics_val = preds_val[[\"pred_0\", \"y\"]].dropna()\n",
    "            pred_metrics_auroc_val = pred_metrics_val.copy()\n",
    "            pred_metrics_auroc_val[\"y\"] = (pred_metrics_auroc_val[\"y\"] == 0.0).astype(float)\n",
    "            auc_val = roc_auc_score(pred_metrics_auroc_val[\"y\"], pred_metrics_auroc_val[\"pred_0\"])\n",
    "            auc_neg_val = roc_auc_score(pred_metrics_auroc_val[\"y\"], -1*pred_metrics_auroc_val[\"pred_0\"])\n",
    "            auc_val = np.max([auc_val, auc_neg_val])\n",
    "            if plot_roc:\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "                fpr, tpr, _ = roc_curve(pred_metrics_auroc_val[\"y\"], pred_metrics_auroc_val[\"pred_0\"])\n",
    "                fpr_, tpr_, _ = roc_curve(pred_metrics_auroc_val[\"y\"], -1*pred_metrics_auroc_val[\"pred_0\"])\n",
    "                for i in range(len(fpr_)):\n",
    "                    roc_curves_list.append({\"fpr\": fpr_[i], \"tpr\": tpr_[i], \"model_type\": model_type, \"rep_type\": rep_type_label, \"feat_set\": feat_set, \"dataset\": \"cv\", \"seed\": 4563})\n",
    "\n",
    "            # pres, rec, thres = precision_recall_curve(pred_metrics_auroc_val[\"y\"], pred_metrics_auroc_val[\"pred_0\"])\n",
    "            # aupr = auc(pres, rec)\n",
    "            # Store CV results as well\n",
    "            test_metrics_list.append({\"n\": len(pred_metrics_val), \"rep_type\": rep_type_label, \"model_type\": model_type, \"feat_sets\": feat_set, \"seed\": hopt_seed,\n",
    "                                        \"spearman_r\": spearmanr(pred_metrics_val[\"pred_0\"], pred_metrics_val[\"y\"])[0], \"pearson_r\": pearsonr(pred_metrics_val[\"pred_0\"], pred_metrics_val[\"y\"])[0],\n",
    "                                            \"rmse\": (np.sqrt(pred_metrics_val[\"pred_0\"] - pred_metrics_val[\"y\"])**2).mean(), \"auroc\": auc_val, \"aupr\": np.nan, \"dataset\": \"cv\"})\n",
    "            for seed in seeds:\n",
    "            #try:\n",
    "                #best_trial = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/opt_study_results_s{seed}.csv\").sort_values(\"value\", ascending=False)[\"number\"][0]\n",
    "                #curr_hopt_df = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/cv_results_{best_trial}_s{seed}.csv\")\n",
    "\n",
    "                curr_preds = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/z_pred_test_s{seed}.csv\")\n",
    "\n",
    "                pred_metrics = curr_preds[[\"pred_0\", \"y\"]].dropna()\n",
    "                pred_metrics_auroc = pred_metrics.copy()\n",
    "                pred_metrics_auroc[\"y\"] = (pred_metrics_auroc[\"y\"] == 0.0).astype(float)\n",
    "                auc = roc_auc_score(pred_metrics_auroc[\"y\"], pred_metrics_auroc[\"pred_0\"])\n",
    "                auc_neg = roc_auc_score(pred_metrics_auroc[\"y\"], -1*pred_metrics_auroc[\"pred_0\"])\n",
    "                auc = np.max([auc, auc_neg])\n",
    "                # pres, rec, thres = precision_recall_curve(pred_metrics_auroc[\"y\"], pred_metrics_auroc[\"pred_0\"])\n",
    "                # aupr = auc(pres, rec)\n",
    "                # Store CV results as well\n",
    "                test_metrics_list.append({\"n\": len(pred_metrics), \"rep_type\": rep_type_label, \"model_type\": model_type, \"feat_sets\": feat_set, \"seed\": seed,\n",
    "                                            \"spearman_r\": spearmanr(pred_metrics[\"pred_0\"], pred_metrics[\"y\"])[0], \"pearson_r\": pearsonr(pred_metrics[\"pred_0\"], pred_metrics[\"y\"])[0],\n",
    "                                                \"rmse\": (np.sqrt(pred_metrics[\"pred_0\"] - pred_metrics[\"y\"])**2).mean(), \"auroc\": auc, \"aupr\": np.nan, \"dataset\": \"test\"})\n",
    "                if plot_roc:\n",
    "                    fpr = dict()\n",
    "                    tpr = dict()\n",
    "                    roc_auc = dict()\n",
    "                    fpr_, tpr_, _ = roc_curve(pred_metrics_auroc[\"y\"], -1*pred_metrics_auroc[\"pred_0\"])\n",
    "                    for i in range(len(fpr_)):\n",
    "                        roc_curves_list.append({\"fpr\": fpr_[i], \"tpr\": tpr_[i], \"model_type\": model_type, \"rep_type\": rep_type_label, \"feat_set\": feat_set, \"dataset\": \"test\", \"seed\": seed})\n",
    "                # except:\n",
    "                #     print(f\"{model_type}, {rep_type}, {ext}, {seed} not found\")\n",
    "                #     continue\n",
    "\n",
    "test_metrics_df = pd.DataFrame.from_dict(test_metrics_list)\n",
    "\n",
    "# Print results on external validation for reporting\n",
    "test_metrics_df.groupby([\"rep_type\", \"model_type\", \"feat_sets\", \"dataset\", \"n\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_roc:\n",
    "    roc_curves_df = pd.DataFrame.from_dict(roc_curves_list)\n",
    "    # Plot ROC curves for clinical+rep+rna ElasticNet PiCo vs VAE (CV)\n",
    "    model_type = \"LogisticRegression\"\n",
    "    rep_type_label = \"PiCo\"\n",
    "    feat_sets_plot = [\"Clinical+Rep+RNA\", \"Clinical+Rep\", \"Clinical+RNA\", \"Clinical\"]\n",
    "    feat_sets_plot = [\"Clinical\", \"Clinical+Rep\"]\n",
    "    roc_curve_data = roc_curves_df[(roc_curves_df[\"model_type\"] == model_type) & (roc_curves_df[\"feat_set\"].isin(feat_sets_plot)) & (roc_curves_df[\"dataset\"] == \"cv\")]\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    roc_curve_data[\"Feature extractor\"] = roc_curve_data[\"rep_type\"]\n",
    "    roc_curve_data[\"Feature set\"] = roc_curve_data[\"feat_set\"]\n",
    "    sns.lineplot(data=roc_curve_data, x=\"fpr\", y=\"tpr\", hue=\"Feature extractor\", style=\"Feature set\", ax=ax, hue_order=[\"PiCo\", \"VAE\"], errorbar=None)\n",
    "    #sns.lineplot(x=fpr, y=tpr, label=f\"{model_type}_{rep_type_label}_{feat_set}\", ci=None)\n",
    "    for line in ax.lines:\n",
    "        line.set_drawstyle(\"steps-post\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", color=\"grey\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.legend(bbox_to_anchor=(0.4, 0.5), loc='upper left', frameon=False, ncol=1, title=None)\n",
    "    sns.despine(ax=ax)\n",
    "    plt.savefig(f\"./figures/transneo/roc_cv_{model_type}_{rep_type_label}_{feat_set}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"./figures/transneo/roc_cv_{model_type}_{rep_type_label}_{feat_set}.svg\", bbox_inches=\"tight\")\n",
    "    # Same for test set\n",
    "    roc_curve_data = roc_curves_df[(roc_curves_df[\"model_type\"] == model_type) & (roc_curves_df[\"feat_set\"].isin(feat_sets_plot)) & (roc_curves_df[\"dataset\"] == \"test\")]\n",
    "    print(roc_curve_data)\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    roc_curve_data[\"Feature extractor\"] = roc_curve_data[\"rep_type\"]\n",
    "    roc_curve_data[\"Feature set\"] = roc_curve_data[\"feat_set\"]\n",
    "    for seed in roc_curve_data[\"seed\"].unique():\n",
    "        sns.lineplot(data=roc_curve_data[roc_curve_data[\"seed\"] == seed], x=\"fpr\", y=\"tpr\", hue=\"Feature extractor\", style=\"Feature set\", ax=ax, alpha=0.3, hue_order=[\"PiCo\", \"VAE\"], errorbar=None, legend=False if seed > roc_curve_data[\"seed\"].unique()[0] else True)\n",
    "    #sns.lineplot(x=fpr, y=tpr, label=f\"{model_type}_{rep_type_label}_{feat_set}\", ci=None)\n",
    "    for line in ax.lines:\n",
    "            line.set_drawstyle(\"steps-post\")\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\", color=\"grey\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.legend(bbox_to_anchor=(0.4, 0.5), loc='upper left', frameon=False, ncol=1, title=None)\n",
    "    sns.despine(ax=ax)\n",
    "    plt.savefig(f\"./figures/transneo/roc_test_{model_type}_{rep_type_label}_{feat_set}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"./figures/transneo/roc_test_{model_type}_{rep_type_label}_{feat_set}.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED TRAIN AND EXT VAL PERFORMANCE -- DATASET FACET\n",
    "# AUROC\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "metric = \"auroc\"\n",
    "model = \"LogisticRegression\"\n",
    "\n",
    "metric_hopt = f\"{metric}\"\n",
    "metric = f\"{metric}\"\n",
    "\n",
    "target = \"resp.pCR\"\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "# palette = {\"PiCo_D\": pal[1], \"VAE\": pal[0],}\n",
    "pal_0_desat = sns.set_hls_values(palette[0], l=0.6, s=0.5)\n",
    "pal_1_desat = sns.set_hls_values(palette[1], l=0.6, s=0.5)\n",
    "pal_cv = {\n",
    "    \"VAE\": palette[1],\n",
    "    \"PiCo\": palette[0],\n",
    "    \"NA\": \"grey\",\n",
    "}\n",
    "pal_ev = {\n",
    "    \"VAE\": palette[1],\n",
    "    \"PiCo\": palette[0],\n",
    "    \"NA\": \"grey\",\n",
    "}\n",
    "\n",
    "plot_order = [\"Clinical\", \"RNA\", \"Clinical+RNA\", \"Rep\", \"Clinical+Rep\", \"Clinical+Rep+RNA\"]\n",
    "\n",
    "facet_order = [\"TransNEO\\nCross-validation\", \"ARTemis+PBCP\\nExternal validation\"]\n",
    "\n",
    "hopt_df_plot = test_metrics_df[(test_metrics_df[\"model_type\"] == model) & (test_metrics_df[\"dataset\"] == \"cv\")].copy()\n",
    "print(hopt_df_plot)\n",
    "\n",
    "hopt_df_plot[\"rep_type_hue\"] = hopt_df_plot[\"rep_type\"].copy()\n",
    "hopt_df_plot.loc[\n",
    "    hopt_df_plot[\"feat_sets\"].isin([\"Clinical+RNA\", \"Clinical\", \"RNA\"]),\n",
    "    \"rep_type_hue\",\n",
    "] = \"NA\"\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(4.5,2.5))\n",
    "\n",
    "## PLOTS CV RESULTS\n",
    "if target == \"RCB.score\":\n",
    "    g1 = sns.pointplot(\n",
    "        data=hopt_df_plot,\n",
    "        y=\"feat_sets\",\n",
    "        x=metric_hopt,\n",
    "        hue=\"rep_type_hue\",\n",
    "        order=plot_order,\n",
    "        palette=pal_cv,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1,\n",
    "        markersize=4,\n",
    "        errorbar=(\"sd\", 1),\n",
    "        capsize=0.25,\n",
    "        marker=\"o\",\n",
    "        err_kws={\"linewidth\": 1.5, \"alpha\": 0.25},\n",
    "        #legend=False,\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    # , errorbar=(\"ci\", 95), capsize=0.1, err_kws={\"linewidth\": 1, \"alpha\": 0.5})\n",
    "else:\n",
    "    g1 = sns.pointplot(\n",
    "        data=hopt_df_plot,\n",
    "        y=\"feat_sets\",\n",
    "        x=metric_hopt,\n",
    "        hue=\"rep_type_hue\",\n",
    "        order=plot_order,\n",
    "        palette=pal_cv,\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1,\n",
    "        markersize=4,\n",
    "        errorbar=(\"sd\", 1),\n",
    "        capsize=0.25,\n",
    "        marker=\"o\",\n",
    "        err_kws={\"linewidth\": 1.5, \"alpha\": 0.25},\n",
    "        #legend=False,\n",
    "        ax=ax[0],\n",
    "    )  # , errorbar=(\"ci\", 95), capsize=0.1, err_kws={\"linewidth\": 1, \"alpha\": 0.5})\n",
    "\n",
    "\n",
    "## PLOTS EXT VAL RESULTS\n",
    "metrics_df_plot = test_metrics_df[(test_metrics_df[\"model_type\"] == model) & (test_metrics_df[\"dataset\"] == \"test\")].copy(deep=True)\n",
    "metrics_df_plot[\"rep_type_hue\"] = metrics_df_plot[\"rep_type\"].copy()\n",
    "metrics_df_plot.loc[\n",
    "    metrics_df_plot[\"feat_sets\"].isin([\"Clinical+RNA\", \"Clinical\", \"RNA\"]), \"rep_type_hue\"\n",
    "] = \"NA\"\n",
    "\n",
    "if target == \"RCB.score\":\n",
    "    sns.pointplot(\n",
    "        data=metrics_df_plot,\n",
    "        y=\"feat_sets\",\n",
    "        x=metric,\n",
    "        hue=\"rep_type_hue\",\n",
    "        order=plot_order,\n",
    "        palette=pal_ev,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=1,\n",
    "        markersize=4,\n",
    "        marker=\"o\",\n",
    "        errorbar=(\"sd\", 1),\n",
    "        capsize=0.25,\n",
    "        err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "        ax=ax[1],\n",
    "        legend=False,\n",
    "    )\n",
    "else:\n",
    "    sns.pointplot(\n",
    "        data=metrics_df_plot,\n",
    "        y=\"feat_sets\",\n",
    "        x=metric,\n",
    "        hue=\"rep_type_hue\",\n",
    "        palette=pal_ev,\n",
    "        order=plot_order,\n",
    "        linestyle=\"-\",\n",
    "        linewidth=1,\n",
    "        markersize=4,\n",
    "        marker=\"o\",\n",
    "        errorbar=(\"sd\", 1),\n",
    "        capsize=0.25,\n",
    "        err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "        ax=ax[1],\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "line_train = Line2D(\n",
    "    [0], [0], label=\"VAE\", color=palette[1], linestyle=\"-\", linewidth=1\n",
    ")\n",
    "line_val = Line2D(\n",
    "    [0], [0], label=\"PiCo\", color=palette[0], linestyle=\"-\", linewidth=1\n",
    ")\n",
    "\n",
    "leg1 = ax[0].legend(\n",
    "    handles=handles[3:],\n",
    "    bbox_to_anchor=(1.0, 1.6),\n",
    "    loc=\"upper center\",\n",
    "    frameon=False,\n",
    "    ncol=3,\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "leg2 = ax[0].legend(\n",
    "    handles=[line_train, line_val],\n",
    "    bbox_to_anchor=(-0.35, 1.45),\n",
    "    loc=\"upper center\",\n",
    "    frameon=False,\n",
    "    ncol=1,\n",
    "    fontsize=10,\n",
    ")\n",
    "\n",
    "ax[0].add_artist(leg1)\n",
    "ax[0].add_artist(leg2)\n",
    "\n",
    "# Rename y ticks\n",
    "names_dict = {\"Clinical\": \"Clinical\", \"RNA\": fr\"RNA\", \"Clinical+RNA\": \"Clinical+RNA\", \"Rep\": fr\"$\\mathbf{{z}}$\", \"Clinical+Rep\": rf\"Clinical+$\\mathbf{{z}}$\", \"Clinical+Rep+RNA\": rf\"Clinical+$\\mathbf{{z}}$+RNA\"}\n",
    "#ax.set_yticks(names_dict.keys())\n",
    "ax[0].set_yticklabels(names_dict.values())\n",
    "\n",
    "#sns.move_legend(ax, \"upper center\", bbox_to_anchor=(.5, -.2), ncol=1, title=None, frameon=False)\n",
    "sns.despine()\n",
    "for i, ax in enumerate(ax):\n",
    "    ax.set_ylabel(\"\")\n",
    "    if target == \"RCB.score\":\n",
    "        if metric == \"test_spearmanr\":\n",
    "            ax.set_xlabel(\"Spearman\\ncorrelation\", fontsize=10)\n",
    "            ax.set_xlim(0.5, 0.82)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "        elif metric == \"test_pearsonr\":\n",
    "            ax.set_xlabel(\"Pearson\\ncorrelation\", fontsize=10)\n",
    "            ax.set_xlim(0.5, 0.82)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "        elif metric == \"test_rmse\":\n",
    "            ax.set_xlabel(\"RMSE\", fontsize=10)\n",
    "            ax.set_xlim(0.85, 1.15)\n",
    "            ax.set_xticks([0.9, 1.0, 1.1], [0.9, 1.0, 1.1])\n",
    "        elif metric == \"auroc\":\n",
    "            ax.set_xlabel(\"AUROC\", fontsize=10)\n",
    "            ax.set_xlim(0.62, 0.95)\n",
    "            ax.set_xticks([0.7, 0.8, 0.9], [0.7, 0.8, 0.9])\n",
    "    else:\n",
    "        if metric == \"auroc\":\n",
    "            ax.set_xlabel(\"AUROC\", fontsize=10)\n",
    "            ax.set_xlim(0.62, 0.95)\n",
    "            ax.set_xticks([0.7, 0.8, 0.9], [0.7, 0.8, 0.9])\n",
    "        elif metric == \"aupr\":\n",
    "            ax.set_xlabel(\"AUPR\", fontsize=10)\n",
    "            ax.set_xlim(0.35, 0.75)\n",
    "            ax.set_xticks([0.4, 0.5, 0.6, 0.7], [0.4, 0.5, 0.6, 0.7])\n",
    "        elif metric == \"test_f1\":\n",
    "            ax.set_xlabel(\"F1 score\", fontsize=10)\n",
    "            ax.set_xlim(0.35, 0.75)\n",
    "            ax.set_xticks([0.4, 0.5, 0.6, 0.7], [0.4, 0.5, 0.6, 0.7])\n",
    "        elif metric == \"test_cross_entropy\":\n",
    "            ax.set_xlabel(\"Cross-entropy\", fontsize=10)\n",
    "            ax.set_xlim(0.3, 0.6)\n",
    "            ax.set_xticks([0.3, 0.4, 0.5, 0.6], [0.3, 0.4, 0.5, 0.6])\n",
    "    ax.set_title(\"\")\n",
    "    ax.text(\n",
    "        s=facet_order[i],\n",
    "        x=0.5,\n",
    "        y=1.1,\n",
    "        transform=ax.transAxes,\n",
    "        fontweight=\"regular\",\n",
    "        horizontalalignment=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "    ax.grid(visible=True, axis=\"x\")\n",
    "    ax.tick_params(labelsize=10)\n",
    "    if i > 0:\n",
    "        sns.despine(left=True, ax=ax)\n",
    "        ax.tick_params(\n",
    "            top=False,\n",
    "            bottom=True,\n",
    "            left=False,\n",
    "            right=False,\n",
    "            labelleft=False,\n",
    "            labelbottom=True,\n",
    "            labelsize=10,\n",
    "        )\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/perf_facet_{target}_{metric}_auroc.png\",\n",
    "    #bbox_extra_artists=(leg1, leg2),\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/perf_facet_{target}_{metric}_auroc.svg\",\n",
    "    #bbox_extra_artists=(leg1, leg2),\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Performance by subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TEST SET RESULTS\n",
    "from utils.comp_utils import calculate_feat_imps, plot_feat_imps_v2\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "seeds = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "feat_sets_subtype = {\"Clinical\": \"_Size.at.diagnosis_7_norep\", \"Clinical+Rep\": \"_Size.at.diagnosis_7\", \"Clinical+RNA\": \"_Size.at.diagnosis_18_norep\", \"Clinical+Rep+RNA\": \"_Size.at.diagnosis_18\", \"RNA\": \"_PGR.log2.tpm_11_norep\", \"Rep\": \"\"}\n",
    "\n",
    "test_metrics_list = []\n",
    "hopt_df = None\n",
    "\n",
    "for feat_set, ext in feat_sets_subtype.items():\n",
    "    for rep_type, rep_type_label in rep_types.items():\n",
    "        for model_type in model_types:\n",
    "            # if rep_type_label == \"PiCo\":\n",
    "            #     try:\n",
    "            #         pred_dict_list, constraints, confounders, feat_imps_df = calculate_feat_imps(enc=rep_type, reg=model_type, model_path=f\"{res_root}/{model_type}_{rep_type + ext}\", target=target, seeds=seeds)\n",
    "            #         if feat_set in [\"Clinical\", \"Clinical+RNA\", \"RNA\"]:\n",
    "            #             zdim = 0\n",
    "            #             norep = True\n",
    "            #         else:\n",
    "            #             zdim = 64\n",
    "            #             norep = False\n",
    "\n",
    "            #         if target == \"RCB.score\":\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_r_{rep_type+ext}\", metric=\"r\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_s_{rep_type+ext}\", metric=\"s\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_rmse_{rep_type+ext}\", metric=\"rmse\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #         else:\n",
    "            #             plot_feat_imps_v2(feat_imps_df, target=target, constraints=constraints, confounders=feat_sets_conf[feat_set], zdim=zdim, enc=rep_type, reg=model_type, experiment=experiment, names_map=names_map, save_path=f\"{model_type}_{target}_auroc_{rep_type+ext}\", metric=\"auroc\", norep=norep, sort_feats=True, top_k=16)\n",
    "            #     except:\n",
    "            #         print(f\"Cannot produce feat imp plot for {model_type}, {rep_type}, {ext}...\")\n",
    "            for seed in seeds:\n",
    "            #try:\n",
    "                #best_trial = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/opt_study_results_s{seed}.csv\").sort_values(\"value\", ascending=False)[\"number\"][0]\n",
    "                #curr_hopt_df = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/cv_results_{best_trial}_s{seed}.csv\")\n",
    "\n",
    "                curr_preds = pd.read_csv(f\"{res_root}/{model_type}_{rep_type + ext}/z_pred_test_s{seed}.csv\")\n",
    "                curr_preds_subtype = pd.read_csv(f\"{res_root}/{model_type}_{rep_type}{feat_sets_subtype['Clinical']}/z_pred_test_s{seed}.csv\")\n",
    "\n",
    "                curr_preds_00 = curr_preds[(curr_preds_subtype[\"c_4\"] < 0) & (curr_preds_subtype[\"c_5\"] < 0)]\n",
    "                curr_preds_10 = curr_preds[(curr_preds_subtype[\"c_4\"] > 0) & (curr_preds_subtype[\"c_5\"] < 0)]\n",
    "                curr_preds_01 = curr_preds[(curr_preds_subtype[\"c_4\"] < 0) & (curr_preds_subtype[\"c_5\"] > 0)]\n",
    "                curr_preds_11 = curr_preds[(curr_preds_subtype[\"c_4\"] > 0) & (curr_preds_subtype[\"c_5\"] > 0)]\n",
    "\n",
    "                subtype_preds = {\"ER-/HER2-\": curr_preds_00, \"ER+/HER2-\": curr_preds_10, \"ER-/HER2+\": curr_preds_01, \"ER+/HER2+\": curr_preds_11}\n",
    "\n",
    "                for subtype, preds in subtype_preds.items():\n",
    "                    pred_metrics = preds[[\"pred_0\", \"y\"]].dropna()\n",
    "                    pred_metrics_auroc = pred_metrics.copy()\n",
    "                    pred_metrics_auroc[\"y\"] = (pred_metrics_auroc[\"y\"] == 0.0).astype(float)\n",
    "                    auc = roc_auc_score(pred_metrics_auroc[\"y\"], pred_metrics_auroc[\"pred_0\"])\n",
    "                    auc_neg = roc_auc_score(pred_metrics_auroc[\"y\"], -1*pred_metrics_auroc[\"pred_0\"])\n",
    "                    auc = np.max([auc, auc_neg])\n",
    "                    test_metrics_list.append({\"subtype\": subtype, \"n\": len(pred_metrics), \"rep_type\": rep_type, \"model_type\": model_type, \"feat_sets\": feat_set, \"seed\": seed,\n",
    "                                                \"spearman_r\": spearmanr(pred_metrics[\"pred_0\"], pred_metrics[\"y\"])[0], \"pearson_r\": pearsonr(pred_metrics[\"pred_0\"], pred_metrics[\"y\"])[0],\n",
    "                                                    \"rmse\": (np.sqrt(pred_metrics[\"pred_0\"] - pred_metrics[\"y\"])**2).mean(), \"auroc\": auc})\n",
    "                    \n",
    "                # except:\n",
    "                #     print(f\"{model_type}, {rep_type}, {ext}, {seed} not found\")\n",
    "                #     continue\n",
    "\n",
    "test_metrics_df = pd.DataFrame.from_dict(test_metrics_list)\n",
    "test_metrics_df[\"dataset\"] = \"test\"\n",
    "\n",
    "# Print results on external validation for reporting\n",
    "test_metrics_df.groupby([\"rep_type\", \"model_type\", \"feat_sets\", \"dataset\", \"subtype\", \"n\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED TRAIN AND EXT VAL PERFORMANCE -- DATASET FACET\n",
    "# AUROC\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "metric = \"auroc\"\n",
    "model = \"LogisticRegression\"\n",
    "target = \"resp.pCR\"\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "# palette = {\"PiCo_D\": pal[1], \"VAE\": pal[0],}\n",
    "pal_0_desat = sns.set_hls_values(palette[0], l=0.6, s=0.5)\n",
    "pal_1_desat = sns.set_hls_values(palette[1], l=0.6, s=0.5)\n",
    "pal_ev = {\n",
    "    \"vae\": palette[1],\n",
    "    \"icovae_MCL1_16\": palette[0],\n",
    "    \"NA\": \"grey\",\n",
    "}\n",
    "\n",
    "plot_order = [\"Clinical\", \"RNA\", \"Clinical+RNA\", \"Rep\", \"Clinical+Rep\", \"Clinical+Rep+RNA\"]\n",
    "\n",
    "facet_order = [\"TransNEO\\nCross-validation\", \"ARTemis+PBCP\\nExternal validation\"]\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(9,2.5), sharex=True)\n",
    "\n",
    "## PLOTS EXT VAL RESULTS\n",
    "metrics_df_plot = test_metrics_df[test_metrics_df[\"model_type\"] == model].copy(deep=True)\n",
    "metrics_df_plot[\"rep_type_hue\"] = metrics_df_plot[\"rep_type\"].copy()\n",
    "metrics_df_plot.loc[\n",
    "    metrics_df_plot[\"feat_sets\"].isin([\"Clinical+RNA\", \"Clinical\", \"RNA\"]), \"rep_type_hue\"\n",
    "] = \"NA\"\n",
    "\n",
    "subtypes = metrics_df_plot[\"subtype\"].unique()\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    curr_metrics_plot = metrics_df_plot[metrics_df_plot[\"subtype\"] == subtypes[i]]\n",
    "    if target == \"RCB.score\":\n",
    "        sns.pointplot(\n",
    "            data=curr_metrics_plot,\n",
    "            y=\"feat_sets\",\n",
    "            x=metric,\n",
    "            hue=\"rep_type_hue\",\n",
    "            order=plot_order,\n",
    "            palette=pal_ev,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1,\n",
    "            markersize=4,\n",
    "            marker=\"o\",\n",
    "            errorbar=(\"sd\", 1),\n",
    "            capsize=0.25,\n",
    "            err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "            ax=ax,\n",
    "            legend=False,\n",
    "        )\n",
    "    else:\n",
    "        sns.pointplot(\n",
    "            data=curr_metrics_plot,\n",
    "            y=\"feat_sets\",\n",
    "            x=metric,\n",
    "            hue=\"rep_type_hue\",\n",
    "            palette=pal_ev,\n",
    "            order=plot_order,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1,\n",
    "            markersize=4,\n",
    "            marker=\"o\",\n",
    "            errorbar=(\"sd\", 1),\n",
    "            capsize=0.25,\n",
    "            err_kws={\"linewidth\": 1.2, \"alpha\": 0.5},\n",
    "            ax=ax,\n",
    "            legend=False,\n",
    "        )\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "    line_train = Line2D(\n",
    "        [0], [0], label=\"VAE\", color=palette[1], linestyle=\"-\", linewidth=1\n",
    "    )\n",
    "    line_val = Line2D(\n",
    "        [0], [0], label=\"PiCo\", color=palette[0], linestyle=\"-\", linewidth=1\n",
    "    )\n",
    "\n",
    "    if i == len(subtypes) - 1:\n",
    "        leg1 = ax.legend(\n",
    "            handles=handles[3:],\n",
    "            bbox_to_anchor=(1.0, 1.6),\n",
    "            loc=\"upper center\",\n",
    "            frameon=False,\n",
    "            ncol=2,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "        leg2 = ax.legend(\n",
    "            handles=[line_train, line_val],\n",
    "            bbox_to_anchor=(-1.15, 1.55),\n",
    "            loc=\"upper center\",\n",
    "            frameon=False,\n",
    "            ncol=2,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "        ax.add_artist(leg1)\n",
    "        ax.add_artist(leg2)\n",
    "\n",
    "    # Rename y ticks\n",
    "    names_dict = {\"Clinical\": \"Clinical\", \"RNA\": \"RNA\", \"Clinical+RNA\": \"Clinical+RNA\", \"Clinical\": \"Clinical\", \"Rep\": rf\"$\\mathbf{{z}}$\", \"Clinical+Rep\": rf\"Clinical+$\\mathbf{{z}}$\", \"Clinical+Rep+RNA\": rf\"Clinical+$\\mathbf{{z}}$+RNA\", \"RNA\": \"RNA\"}\n",
    "    #ax.set_yticks(names_dict.keys())\n",
    "    ax.set_yticklabels(names_dict.values())\n",
    "\n",
    "    #sns.move_legend(ax, \"upper center\", bbox_to_anchor=(.5, -.2), ncol=1, title=None, frameon=False)\n",
    "    sns.despine()\n",
    "    ax.set_ylabel(\"\")\n",
    "    if target == \"RCB.score\":\n",
    "        if metric == \"spearman_r\":\n",
    "            ax.set_xlabel(\"Spearman\\ncorrelation\", fontsize=10)\n",
    "            ax.set_xlim(0.0, 1.0)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "        elif metric == \"pearson_r\":\n",
    "            ax.set_xlabel(\"Pearson\\ncorrelation\", fontsize=10)\n",
    "            ax.set_xlim(0.5, 0.82)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8], [0.5, 0.6, 0.7, 0.8])\n",
    "        elif metric == \"test_rmse\":\n",
    "            ax.set_xlabel(\"RMSE\", fontsize=10)\n",
    "            ax.set_xlim(0.85, 1.15)\n",
    "            ax.set_xticks([0.9, 1.0, 1.1], [0.9, 1.0, 1.1])\n",
    "        if metric == \"auroc\":\n",
    "            ax.set_xlabel(\"AUROC\", fontsize=10)\n",
    "            ax.set_xlim(0.45, 1.0)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8, 0.9], [0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "    else:\n",
    "        if metric == \"auroc\":\n",
    "            ax.set_xlabel(\"AUROC\", fontsize=10)\n",
    "            ax.set_xlim(0.45, 1.02)\n",
    "            ax.set_xticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0], [0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "        elif metric == \"aupr\":\n",
    "            ax.set_xlabel(\"AUPR\", fontsize=10)\n",
    "            ax.set_xlim(0.35, 0.75)\n",
    "            ax.set_xticks([0.4, 0.5, 0.6, 0.7], [0.4, 0.5, 0.6, 0.7])\n",
    "        elif metric == \"f1\":\n",
    "            ax.set_xlabel(\"F1 score\", fontsize=10)\n",
    "            ax.set_xlim(0.35, 0.75)\n",
    "            ax.set_xticks([0.4, 0.5, 0.6, 0.7], [0.4, 0.5, 0.6, 0.7])\n",
    "        elif metric == \"cross_entropy\":\n",
    "            ax.set_xlabel(\"Cross-entropy\", fontsize=10)\n",
    "            ax.set_xlim(0.3, 0.6)\n",
    "            ax.set_xticks([0.3, 0.4, 0.5, 0.6], [0.3, 0.4, 0.5, 0.6])\n",
    "    ax.set_title(\"\")\n",
    "    ax.text(\n",
    "        s=f\"{subtypes[i]}\\n(n={curr_metrics_plot['n'].iloc[0]})\",\n",
    "        x=0.5,\n",
    "        y=1.1,\n",
    "        transform=ax.transAxes,\n",
    "        fontweight=\"regular\",\n",
    "        horizontalalignment=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "    ax.grid(visible=True, axis=\"x\")\n",
    "    ax.tick_params(labelsize=10)\n",
    "    if i > 0:\n",
    "        sns.despine(left=False, ax=ax)\n",
    "        ax.tick_params(\n",
    "            top=False,\n",
    "            bottom=True,\n",
    "            left=False,\n",
    "            right=False,\n",
    "            labelleft=False,\n",
    "            labelbottom=True,\n",
    "            labelsize=10,\n",
    "        )\n",
    "    #ax.set_xlabel(\"Spearman correlation\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/perf_facet_{target}_{metric}_subtype.png\",\n",
    "    #bbox_extra_artists=(leg1, leg2),\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/perf_facet_{target}_{metric}_subtype.svg\",\n",
    "    #bbox_extra_artists=(leg1, leg2),\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Representation associations with outcome and other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Single feature scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCATTER PLOT FEATURES\n",
    "from scipy.stats import pointbiserialr, spearmanr\n",
    "from functools import partial\n",
    "\n",
    "def rep_renamer(x, constraints, prefix=\"z\"):\n",
    "    dim = int(x.split(\"_\")[1])\n",
    "    if dim < len(constraints):\n",
    "        return f\"{prefix}_{constraints[dim]}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "rep_type = \"icovae_MCL1_16\"\n",
    "target = \"resp.pCR\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "model_type = \"LogisticRegression\"\n",
    "\n",
    "def pbc_corr(x1, x2):\n",
    "    u_1 = len(np.unique(x1))\n",
    "    u_2 = len(np.unique(x2))\n",
    "\n",
    "    if min(u_1, u_2) == 2:\n",
    "        res = pointbiserialr(x1, x2)\n",
    "    else:\n",
    "        res = spearmanr(x1, x2)\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "ext = \"_Size.at.diagnosis_18\"\n",
    "\n",
    "model_path = f\"{res_root}/{model_type}_{rep_type + ext}\"\n",
    "\n",
    "\n",
    "corrs = []\n",
    "corrs_val = []\n",
    "for seed in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "\n",
    "    # LOAD ARGUMENTS\n",
    "    with open(f\"{model_path}/args_best_s{seed}.txt\", \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    constraints = args[\"constraints\"]\n",
    "    n_constraints = len(constraints)\n",
    "    confounders = args[\"confounders\"]\n",
    "    if confounders is None:\n",
    "        n_confounders = 0\n",
    "    else:\n",
    "        n_confounders = len(confounders)\n",
    "\n",
    "    # Load predictions\n",
    "    test_z = pd.read_csv(f\"{model_path}/z_pred_test_s{seed}.csv\")\n",
    "    train_z = pd.read_csv(f\"{model_path}/z_pred_train_s{seed}.csv\")\n",
    "\n",
    "    # Rename test df\n",
    "    test_z_rep_z = test_z.iloc[:, test_z.columns.str.startswith(\"z\")]\n",
    "    test_z_rep_c =  test_z.iloc[:, test_z.columns.str.startswith(\"c\")]\n",
    "    test_z_rep_z = test_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    test_z_rep_c = test_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "\n",
    "    test_z_rep = pd.concat([test_z_rep_z, test_z_rep_c], axis=1)\n",
    "\n",
    "    # Rename train df\n",
    "    train_z_rep_z = train_z.iloc[:, train_z.columns.str.startswith(\"z\")]\n",
    "    train_z_rep_c =  train_z.iloc[:, train_z.columns.str.startswith(\"c\")]\n",
    "    train_z_rep_z = train_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    train_z_rep_c = train_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "\n",
    "    train_z_rep = pd.concat([train_z_rep_z, train_z_rep_c], axis=1)\n",
    "\n",
    "    feat_top_corr = pd.DataFrame(train_z_rep.corr(method=\"spearman\"))\n",
    "    feat_top_corr[\"seed\"] = seed\n",
    "    corrs.append(feat_top_corr)\n",
    "\n",
    "    feat_top_corr_val = pd.DataFrame(test_z_rep.corr(method=\"spearman\"))\n",
    "    feat_top_corr_val[\"seed\"] = seed\n",
    "    corrs_val.append(feat_top_corr_val)\n",
    "\n",
    "# corrs = pd.DataFrame(corrs)\n",
    "# corrs_val = pd.DataFrame(corrs_val)\n",
    "\n",
    "# r, p = pearsonr(x[feat_1], x[feat_2])\n",
    "# print(f\"{p*len(x.columns):.3e}\")\n",
    "\n",
    "# f, ax = plt.subplots(1,1, figsize=(2,2))\n",
    "# sns.scatterplot(data=x, x=feat_1, y=feat_2, hue=hue, ax=ax, palette=\"Set2\")\n",
    "# sns.despine(ax=ax)\n",
    "# ax.text(s=f\"$r_{{p}} = {r:.3f}, p = {p*len(x.columns):.3f}$\", x=0.1, y=1.0, transform=ax.transAxes, size=8)\n",
    "\n",
    "# feat_1_split = feat_1.split(\"_\")\n",
    "# if feat_1_split[0] == \"z\":\n",
    "#     ax.set_xlabel(rf\"$z_{{{feat_1_split[1]}}}$\")\n",
    "# else:\n",
    "#     ax.set_xlabel(names_map[feat_1])\n",
    "\n",
    "# ax.set_ylabel(names_map[feat_2])\n",
    "\n",
    "\n",
    "# plt.savefig(f\"./ext_val_sammut/figures/corr_{feat_1}_{feat_2}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "# plt.savefig(f\"./ext_val_sammut/figures/corr_{feat_1}_{feat_2}.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 All features correlation matrix heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPRESENTATION CORRELATION WITH OTHER FEATURES\n",
    "val = False\n",
    "\n",
    "if val:\n",
    "    corrs_df = pd.concat(corrs_val, axis=0).reset_index().groupby(\"index\").mean().reset_index()\n",
    "else:\n",
    "    corrs_df = pd.concat(corrs, axis=0).reset_index().groupby(\"index\").mean().reset_index()\n",
    "\n",
    "pal = sns.color_palette(\"colorblind\")\n",
    "\n",
    "\n",
    "def feat_labeller(x):\n",
    "    if x[0] == \"z\":\n",
    "        return pal[0]\n",
    "    elif x in [\n",
    "        \"ESR1.log2.tpm\",\n",
    "        \"PGR.log2.tpm\",\n",
    "        \"ERBB2.log2.tpm\",\n",
    "        \"GGI.ssgsea.notnorm\",\n",
    "        \"Swanton.PaclitaxelScore\",\n",
    "        \"ESC.ssgsea.notnorm\",\n",
    "    ]:\n",
    "        return pal[1]\n",
    "    elif x in [\"Danaher.Mast.cells\", \"STAT1.ssgsea.notnorm\", \"TIDE.Exclusion\"]:\n",
    "        return pal[2]\n",
    "    elif x in [\n",
    "        \"CodingMuts.PIK3CA\",\n",
    "        \"CodingMuts.TP53\",\n",
    "        \"All.TMB\",\n",
    "        \"Coding.TMB\",\n",
    "        \"Expressed.NAg\",\n",
    "        \"\",\n",
    "    ]:\n",
    "        return pal[3]\n",
    "    else:\n",
    "        return pal[4]\n",
    "\n",
    "\n",
    "# row_colors = corrs_df[\"index\"].apply(lambda x: feat_labeller(x))\n",
    "# row_colors.index = corrs_df[\"index\"]\n",
    "# row_colors = row_colors.rename(lambda x: x.split(\"_\"))\n",
    "# row_colors = row_colors.rename(lambda x: f\"$z_{{{x[1]}}}$\" if len(x) > 1 else names_map[x[0]])\n",
    "# print(row_colors)\n",
    "\n",
    "corrs_df = corrs_df.set_index(\"index\")\n",
    "\n",
    "col_plot = [\n",
    "    not col.split(\"_\")[1].isdigit() and (col.split(\"_\")[0] == \"z\") if (len(col.split(\"_\")) > 1) else False\n",
    "    for col in corrs_df.columns\n",
    "]\n",
    "\n",
    "corrs_df = corrs_df.loc[~corrs_df.index.str.startswith(\"z\"), col_plot].reset_index()\n",
    "\n",
    "corrs_df[\"index\"] = corrs_df[\"index\"].apply(lambda x: x.split(\"_\"))\n",
    "corrs_df[\"index\"] = corrs_df[\"index\"].apply(\n",
    "    lambda x: f\"$z_{{{x[1]}}}$\" if (x[0] == \"z\") else names_map[x[1]]\n",
    ")\n",
    "\n",
    "split_str = \"_\"\n",
    "\n",
    "corrs_df = corrs_df.set_index(\"index\").rename(\n",
    "     lambda x: rf\"$z_{{{x.split(split_str)[1]}}}$\", axis=1\n",
    ")\n",
    "\n",
    "print(np.min(corrs_df))\n",
    "print(np.max(corrs_df))\n",
    "\n",
    "# Drop columns with all low values\n",
    "corrs_df = corrs_df.T\n",
    "#for col in corrs_df:\n",
    "    # If all value in column less than 0.2 then drop\n",
    "    # if (corrs_df[col].abs() < 0.2).all():\n",
    "    #     corrs_df = corrs_df.drop(col, axis=1)\n",
    "\n",
    "fig_width = len(corrs_df.columns)\n",
    "\n",
    "g = sns.clustermap(\n",
    "    corrs_df.T,\n",
    "    yticklabels=True,\n",
    "    xticklabels=True,\n",
    "    figsize=(4.5, fig_width / 4.6),\n",
    "    method=\"complete\",\n",
    "    cmap=sns.diverging_palette(220, 10, s=100, l=25, as_cmap=True),\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    center=0,\n",
    "    cbar_pos=(0.75, 0.02, 0.02, 0.125),\n",
    "    dendrogram_ratio=0.1,\n",
    ")\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize=12)\n",
    "g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize=10)\n",
    "g.ax_heatmap.set_ylabel(\"\")\n",
    "g.ax_heatmap.set_xlabel(\"\")\n",
    "\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/feat_corr_hm_{rep_type}_{'val' if val else 'train'}.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/feat_corr_hm_{rep_type}_{'val' if val else 'train'}.svg\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPRESENTATION CORRELATION WITH ITSELF\n",
    "val = True\n",
    "if val:\n",
    "    corrs_df = pd.concat(corrs_val, axis=0).reset_index().groupby(\"index\").mean().reset_index()\n",
    "else:\n",
    "    corrs_df = pd.concat(corrs, axis=0).reset_index().groupby(\"index\").mean().reset_index()\n",
    "\n",
    "corrs_df = corrs_df.set_index(\"index\")\n",
    "\n",
    "col_plot = [\n",
    "    not col.split(\"_\")[1].isdigit() if (col.split(\"_\")[0] == \"z\") else False\n",
    "    for col in corrs_df.columns\n",
    "]\n",
    "\n",
    "row_plot = [\n",
    "    not row.split(\"_\")[1].isdigit() if (row.split(\"_\")[0] == \"z\") else False\n",
    "    for row in corrs_df.index\n",
    "]\n",
    "\n",
    "corrs_df = corrs_df.loc[row_plot, col_plot].reset_index()\n",
    "\n",
    "print(corrs_df)\n",
    "\n",
    "corrs_df[\"index\"] = corrs_df[\"index\"].apply(lambda x: x.split(\"_\"))\n",
    "corrs_df[\"index\"] = corrs_df[\"index\"].apply(\n",
    "    lambda x: f\"$z_{{{x[1]}}}$\" if len(x) > 1 else names_map[x[0]]\n",
    ")\n",
    "\n",
    "split_str = \"_\"\n",
    "\n",
    "corrs_df = corrs_df.set_index(\"index\").rename(\n",
    "    lambda x: rf\"$z_{{{x.split(split_str)[1]}}}$\", axis=1\n",
    ")\n",
    "\n",
    "g = sns.clustermap(\n",
    "    corrs_df,\n",
    "    square=True,\n",
    "    yticklabels=True,\n",
    "    xticklabels=True,\n",
    "    figsize=(3.25, 3),\n",
    "    method=\"complete\",\n",
    "    cmap=sns.diverging_palette(220, 10, s=100, l=25, as_cmap=True),\n",
    "    cbar_pos=(0.77, 0.02, 0.02, 0.125),\n",
    "    dendrogram_ratio=0.1,\n",
    "    center=0.0,\n",
    "    vmax=1,\n",
    "    vmin=-1,\n",
    ")\n",
    "g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize=10)\n",
    "g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_ymajorticklabels(), fontsize=10)\n",
    "g.ax_heatmap.set_ylabel(\"\")\n",
    "\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/rep_corr_hm_{rep_type}_{'val' if val else 'train'}.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"./figures/transneo/rep_corr_hm_{rep_type}_{'val' if val else 'train'}.svg\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Single variable associations with outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION WITH RCB SCORE\n",
    "from scipy.stats import fisher_exact, mannwhitneyu\n",
    "import json\n",
    "from scipy.stats import pointbiserialr, spearmanr\n",
    "from functools import partial\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def rep_renamer(x, constraints, prefix=\"z\"):\n",
    "    dim = int(x.split(\"_\")[1])\n",
    "    if dim < len(constraints):\n",
    "        return f\"{prefix}_{constraints[dim]}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "rep_type = \"icovae_MCL1_16\"\n",
    "target = \"resp.pCR\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "model_type = \"LogisticRegression\"\n",
    "\n",
    "def pbc_corr(x1, x2):\n",
    "    u_1 = len(np.unique(x1))\n",
    "    u_2 = len(np.unique(x2))\n",
    "\n",
    "    if min(u_1, u_2) == 2:\n",
    "        res = pointbiserialr(x1, x2)\n",
    "    else:\n",
    "        res = spearmanr(x1, x2)\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "ext = \"_Size.at.diagnosis_18\"\n",
    "\n",
    "model_path = f\"{res_root}/{model_type}_{rep_type + ext}\"\n",
    "\n",
    "\n",
    "corrs = []\n",
    "corrs_val = []\n",
    "for seed in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "\n",
    "    # LOAD ARGUMENTS\n",
    "    with open(f\"{model_path}/args_best_s{seed}.txt\", \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    constraints = args[\"constraints\"]\n",
    "    n_constraints = len(constraints)\n",
    "    confounders = args[\"confounders\"]\n",
    "    if confounders is None:\n",
    "        n_confounders = 0\n",
    "    else:\n",
    "        n_confounders = len(confounders)\n",
    "\n",
    "    # Load predictions\n",
    "    test_z = pd.read_csv(f\"{model_path}/z_pred_test_s{seed}.csv\")\n",
    "    train_z = pd.read_csv(f\"{model_path}/z_pred_train_s{seed}.csv\")\n",
    "\n",
    "    # Rename test df\n",
    "    test_z_rep_z = test_z.iloc[:, test_z.columns.str.startswith(\"z\")]\n",
    "    test_z_rep_c =  test_z.iloc[:, test_z.columns.str.startswith(\"c\")]\n",
    "    test_z_rep_y = test_z[[\"y\"]]\n",
    "    test_z_rep_z = test_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    test_z_rep_c = test_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    test_z_rep_y = test_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    test_z_rep = pd.concat([test_z_rep_z, test_z_rep_c, test_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    # Rename train df\n",
    "    train_z_rep_z = train_z.iloc[:, train_z.columns.str.startswith(\"z\")]\n",
    "    train_z_rep_c =  train_z.iloc[:, train_z.columns.str.startswith(\"c\")]\n",
    "    train_z_rep_y = train_z[[\"y\"]]\n",
    "    train_z_rep_z = train_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    train_z_rep_c = train_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    train_z_rep_y = train_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    train_z_rep = pd.concat([train_z_rep_z, train_z_rep_c, train_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    for col in train_z_rep.columns:\n",
    "        if col != target:\n",
    "            # Calculate AUROC for this feature\n",
    "            if target == \"resp.pCR\":\n",
    "                auc = roc_auc_score(train_z_rep[target], train_z_rep[col])\n",
    "                auc_neg = roc_auc_score(train_z_rep[target], -1*train_z_rep[col])\n",
    "                auc = np.max([auc, auc_neg])\n",
    "            else:\n",
    "                auc = np.nan\n",
    "            corrs.append({\"feat\": col, \"seed\": seed, \"spearmanr\": spearmanr(train_z_rep[col], train_z_rep[target])[0], \"pearsonr\": pearsonr(train_z_rep[col], train_z_rep[target])[0], \"auroc\": auc})\n",
    "\n",
    "    for col in test_z_rep.columns:\n",
    "        if col != target:\n",
    "            if target == \"resp.pCR\":\n",
    "                auc = roc_auc_score(test_z_rep[target], test_z_rep[col])\n",
    "                auc_neg = roc_auc_score(test_z_rep[target], -1*test_z_rep[col])\n",
    "                auc = np.max([auc, auc_neg])\n",
    "            else:\n",
    "                auc = np.nan\n",
    "            corrs_val.append({\"feat\": col, \"seed\": seed, \"spearmanr\": spearmanr(test_z_rep[col], test_z_rep[target])[0], \"pearsonr\": pearsonr(test_z_rep[col], test_z_rep[target])[0], \"auroc\": auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"spearmanr\", \"pearsonr\", \"auroc\"]:\n",
    "\n",
    "    palette = sns.color_palette(\"colorblind\")[2:]\n",
    "\n",
    "    corrs_df_val = pd.DataFrame.from_dict(corrs_val).reset_index()\n",
    "\n",
    "    corrs_df = pd.DataFrame.from_dict(corrs).reset_index()\n",
    "\n",
    "    corrs_df_val[\"dataset\"] = \"ARTemis+PBCP\"\n",
    "    corrs_df[\"dataset\"] = \"TransNEO\"\n",
    "\n",
    "    corrs_df = pd.concat([corrs_df_val, corrs_df], axis=0)\n",
    "\n",
    "    corrs_df[\"mean_spearmanr\"] = corrs_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"spearmanr\"].astype(float)\n",
    "    corrs_df[\"mean_pearsonr\"] = corrs_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"pearsonr\"].astype(float)\n",
    "\n",
    "    corrs_df[\"abs_spearmanr\"] = corrs_df[\"spearmanr\"].abs().astype(float)\n",
    "    corrs_df[\"abs_pearsonr\"] = corrs_df[\"pearsonr\"].abs().astype(float)\n",
    "\n",
    "    corrs_df[\"mean_auroc\"] = corrs_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"auroc\"].astype(float)\n",
    "    corrs_df[\"abs_auroc\"] = corrs_df[\"auroc\"].abs().astype(float)\n",
    "\n",
    "    corrs_df[\"feat\"] = corrs_df[\"feat\"].apply(lambda x: x.split(\"_\"))\n",
    "    corrs_df[\"feat\"] = corrs_df[\"feat\"].apply(\n",
    "        lambda x: f\"$z_{{{x[1]}}}$\" if x[0] == \"z\" else names_map[x[1]]\n",
    "    )\n",
    "\n",
    "    corrs_df = corrs_df.sort_values(by=[\"dataset\", f\"mean_{metric.split('_')[-1]}\"], key=lambda x: abs(x) if x.dtypes == \"float64\" else x, ascending=[False, False])\n",
    "    print(corrs_df)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(2.5,3))\n",
    "\n",
    "    sns.pointplot(data=corrs_df, x=metric, y=\"feat\", hue=\"dataset\", ax=ax, errorbar=(\"sd\", 1),\n",
    "        capsize=0.25,\n",
    "        linestyle=\"none\",\n",
    "        markersize=3,\n",
    "        err_kws={\"linewidth\": 1, \"alpha\": 0.5},\n",
    "        palette=palette,)\n",
    "\n",
    "    if metric == \"abs_spearmanr\":\n",
    "        ax.set_xlabel(\"Abs. Spearman correlation\")\n",
    "        ax.set_xticks([-0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6])\n",
    "    elif metric == \"abs_pearsonr\":\n",
    "        ax.set_xlabel(\"Abs. Pearson correlation\")\n",
    "        ax.set_xticks([-0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6])\n",
    "    elif metric == \"spearmanr\":\n",
    "        ax.set_xlabel(\"Spearman correlation\")\n",
    "        ax.set_xticks([-0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6])\n",
    "    elif metric == \"pearsonr\":\n",
    "        ax.set_xlabel(\"Pearson correlation\")\n",
    "        ax.set_xticks([-0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6])\n",
    "    elif metric == \"auroc\":\n",
    "        ax.set_xlabel(\"AUROC\")\n",
    "        ax.set_xlim(0.4, 0.8)\n",
    "        ax.set_xticks([0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.tick_params(\n",
    "        top=False,\n",
    "        bottom=True,\n",
    "        left=True,\n",
    "        right=False,\n",
    "        labelleft=True,\n",
    "        labelbottom=True,\n",
    "        labelsize=10,\n",
    "            )\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    ax.grid(visible=True, axis=\"x\")\n",
    "\n",
    "    ax.set_ylim(15.5,-0.5)\n",
    "    ax.axvline(0, c=\"grey\", lw=0.5)\n",
    "\n",
    "    ax.legend(frameon=False, title=\"\", ncol=1, bbox_to_anchor=(0.5,1.0), loc=\"lower center\", fontsize=10)#, labels=[\"TransNEO\", \"ARTemis+PBCP\"])\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/{metric}_assocs_{rep_type}.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/{metric}_assocs_{rep_type}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_df.groupby([\"feat\", \"dataset\"]).mean().sort_values(\n",
    "    \"abs_spearmanr\", ascending=False\n",
    ").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION WITH RCB SCORE SEPARATED BY SUBTYPE\n",
    "\n",
    "from scipy.stats import fisher_exact, mannwhitneyu\n",
    "import json\n",
    "from scipy.stats import pointbiserialr, spearmanr\n",
    "from functools import partial\n",
    "\n",
    "def rep_renamer(x, constraints, prefix=\"z\"):\n",
    "    dim = int(x.split(\"_\")[1])\n",
    "    if dim < len(constraints):\n",
    "        return f\"{prefix}_{constraints[dim]}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "rep_type = \"icovae_MCL1_16\"\n",
    "target = \"resp.pCR\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "model_type = \"LogisticRegression\"\n",
    "\n",
    "def pbc_corr(x1, x2):\n",
    "    u_1 = len(np.unique(x1))\n",
    "    u_2 = len(np.unique(x2))\n",
    "\n",
    "    if min(u_1, u_2) == 2:\n",
    "        res = pointbiserialr(x1, x2)\n",
    "    else:\n",
    "        res = spearmanr(x1, x2)\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}_new/{experiment}/pico\"\n",
    "ext = \"_Size.at.diagnosis_18\"\n",
    "\n",
    "model_path = f\"{res_root}/{model_type}_{rep_type + ext}\"\n",
    "\n",
    "\n",
    "corrs_subtype = []\n",
    "corrs_subtype_val = []\n",
    "for seed in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "\n",
    "    # LOAD ARGUMENTS\n",
    "    with open(f\"{model_path}/args_best_s{seed}.txt\", \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    constraints = args[\"constraints\"]\n",
    "    n_constraints = len(constraints)\n",
    "    confounders = args[\"confounders\"]\n",
    "    if confounders is None:\n",
    "        n_confounders = 0\n",
    "    else:\n",
    "        n_confounders = len(confounders)\n",
    "\n",
    "    # Load predictions\n",
    "    test_z = pd.read_csv(f\"{model_path}/z_pred_test_s{seed}.csv\")\n",
    "    train_z = pd.read_csv(f\"{model_path}/z_pred_train_s{seed}.csv\")\n",
    "\n",
    "    # Rename test df\n",
    "    test_z_rep_z = test_z.iloc[:, test_z.columns.str.startswith(\"z\")]\n",
    "    test_z_rep_c =  test_z.iloc[:, test_z.columns.str.startswith(\"c\")]\n",
    "    test_z_rep_y = test_z[[\"y\"]]\n",
    "    test_z_rep_z = test_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    test_z_rep_c = test_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    test_z_rep_y = test_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    test_z_rep = pd.concat([test_z_rep_z, test_z_rep_c, test_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    # Rename train df\n",
    "    train_z_rep_z = train_z.iloc[:, train_z.columns.str.startswith(\"z\")]\n",
    "    train_z_rep_c =  train_z.iloc[:, train_z.columns.str.startswith(\"c\")]\n",
    "    train_z_rep_y = train_z[[\"y\"]]\n",
    "    train_z_rep_z = train_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    train_z_rep_c = train_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    train_z_rep_y = train_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    train_z_rep = pd.concat([train_z_rep_z, train_z_rep_c, train_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    train_z_rep_00 = train_z_rep[(train_z_rep[\"c_ER.status\"] < 0) & (train_z_rep[\"c_HER2.status\"] < 0)]\n",
    "    train_z_rep_10 = train_z_rep[(train_z_rep[\"c_ER.status\"] > 0) & (train_z_rep[\"c_HER2.status\"] < 0)]\n",
    "    train_z_rep_01 = train_z_rep[(train_z_rep[\"c_ER.status\"] < 0) & (train_z_rep[\"c_HER2.status\"] > 0)]\n",
    "    train_z_rep_11 = train_z_rep[(train_z_rep[\"c_ER.status\"] > 0) & (train_z_rep[\"c_HER2.status\"] > 0)]\n",
    "\n",
    "    test_z_rep_00 = test_z_rep[(test_z_rep[\"c_ER.status\"] < 0) & (test_z_rep[\"c_HER2.status\"] < 0)]\n",
    "    test_z_rep_10 = test_z_rep[(test_z_rep[\"c_ER.status\"] > 0) & (test_z_rep[\"c_HER2.status\"] < 0)]\n",
    "    test_z_rep_01 = test_z_rep[(test_z_rep[\"c_ER.status\"] < 0) & (test_z_rep[\"c_HER2.status\"] > 0)]\n",
    "    test_z_rep_11 = test_z_rep[(test_z_rep[\"c_ER.status\"] > 0) & (test_z_rep[\"c_HER2.status\"] > 0)]\n",
    "\n",
    "    reps_subtype = {\"ER-/HER2-\": (train_z_rep_00, test_z_rep_00), \"ER+/HER2-\": (train_z_rep_10, test_z_rep_10), \"ER-/HER2+\": (train_z_rep_01, test_z_rep_01), \"ER+/HER2+\": (train_z_rep_11, test_z_rep_11)}\n",
    "\n",
    "    for subtype, (train_rep, test_rep) in reps_subtype.items():\n",
    "        for col in train_rep.columns:\n",
    "            if target == \"resp.pCR\":\n",
    "                auc = roc_auc_score(train_rep[target], train_rep[col])\n",
    "                auc_neg = roc_auc_score(train_rep[target], -1*train_rep[col])\n",
    "                auc = np.max([auc, auc_neg])\n",
    "            else:\n",
    "                auc = np.nan\n",
    "            if col != target:\n",
    "                corrs_subtype.append({\"subtype\": subtype, \"feat\": col, \"seed\": seed, \"spearmanr\": spearmanr(train_rep[col], train_rep[target])[0], \"pearsonr\": pearsonr(train_rep[col], train_rep[target])[0], \"auroc\": auc})\n",
    "\n",
    "        for col in test_rep.columns:\n",
    "            if target == \"resp.pCR\":\n",
    "                auc = roc_auc_score(test_rep[target], test_rep[col])\n",
    "                auc_neg = roc_auc_score(test_rep[target], -1*test_rep[col])\n",
    "                auc = np.max([auc, auc_neg])\n",
    "            else:\n",
    "                auc = np.nan\n",
    "            if col != target:\n",
    "                corrs_subtype_val.append({\"subtype\": subtype, \"feat\": col, \"seed\": seed, \"spearmanr\": spearmanr(test_rep[col], test_rep[target])[0], \"pearsonr\": pearsonr(test_rep[col], test_rep[target])[0], \"auroc\": auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"spearmanr\", \"pearsonr\", \"auroc\"]:\n",
    "\n",
    "    palette = sns.color_palette(\"colorblind\")[2:]\n",
    "\n",
    "    corrs_subtype_df_val = pd.DataFrame.from_dict(corrs_subtype_val).reset_index()\n",
    "\n",
    "    corrs_subtype_df = pd.DataFrame.from_dict(corrs_subtype).reset_index()\n",
    "\n",
    "    corrs_subtype_df_val[\"dataset\"] = \"ARTemis+PBCP\"\n",
    "    corrs_subtype_df[\"dataset\"] = \"TransNEO\"\n",
    "\n",
    "    corrs_subtype_df = pd.concat([corrs_subtype_df_val, corrs_subtype_df], axis=0).reset_index()\n",
    "\n",
    "    corrs_subtype_df[\"mean_spearmanr\"] = corrs_subtype_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"spearmanr\"].astype(float)\n",
    "    corrs_subtype_df[\"mean_pearsonr\"] = corrs_subtype_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"pearsonr\"].astype(float)\n",
    "\n",
    "    corrs_subtype_df[\"abs_spearmanr\"] = corrs_subtype_df[\"spearmanr\"].abs().astype(float)\n",
    "    corrs_subtype_df[\"abs_pearsonr\"] = corrs_subtype_df[\"pearsonr\"].abs().astype(float)\n",
    "\n",
    "    corrs_subtype_df[\"mean_auroc\"] = corrs_subtype_df.groupby([\"dataset\", \"feat\"]).transform(\"mean\")[\"auroc\"].astype(float)\n",
    "    corrs_subtype_df[\"abs_auroc\"] = corrs_subtype_df[\"auroc\"].abs().astype(float)\n",
    "\n",
    "    corrs_subtype_df[\"feat\"] = corrs_subtype_df[\"feat\"].apply(lambda x: x.split(\"_\"))\n",
    "    corrs_subtype_df[\"feat\"] = corrs_subtype_df[\"feat\"].apply(\n",
    "        lambda x: f\"$z_{{{x[1]}}}$\" if x[0] == \"z\" else names_map[x[1]]\n",
    "    )\n",
    "\n",
    "    # Create a new empty DataFrame to store sorted entries\n",
    "    sorted_corrs = []\n",
    "\n",
    "    # Sort 'feat' within each subtype independently\n",
    "    for subtype, df_sub in corrs_subtype_df.groupby(\"subtype\"):\n",
    "        # Compute mean correlation across datasets for ordering\n",
    "        order = (\n",
    "            df_sub.groupby(\"feat\")[metric]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False, key=abs)\n",
    "            .index\n",
    "        )\n",
    "\n",
    "        # Convert feat to ordered categorical\n",
    "        df_sub = df_sub.copy()\n",
    "        df_sub[\"feat\"] = pd.Categorical(df_sub[\"feat\"], categories=order, ordered=True)\n",
    "\n",
    "        sorted_corrs.append(df_sub)\n",
    "\n",
    "    # Concatenate sorted chunks\n",
    "    corrs_subtype_df = pd.concat(sorted_corrs, axis=0)\n",
    "\n",
    "    # Store your subtypes\n",
    "    subtypes = corrs_subtype_df[\"subtype\"].unique()\n",
    "\n",
    "    # Set color palette\n",
    "    palette = sns.color_palette(\"colorblind\")[2:]\n",
    "\n",
    "    # Create subplots with one axis per subtype\n",
    "    fig, axes = plt.subplots(1, len(subtypes), figsize=(3 * len(subtypes), 3.5), sharex=True, sharey=False)\n",
    "\n",
    "    if len(subtypes) == 1:\n",
    "        axes = [axes]  # Make iterable if only one axis\n",
    "\n",
    "    for ax, subtype in zip(axes, subtypes):\n",
    "        df_sub = corrs_subtype_df[corrs_subtype_df[\"subtype\"] == subtype].copy()\n",
    "\n",
    "        # Get ordering for this facet\n",
    "        order = (\n",
    "            df_sub.groupby(\"feat\")[metric]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False, key=abs)\n",
    "            .head(15)\n",
    "            .index\n",
    "        )\n",
    "        df_sub[\"feat\"] = pd.Categorical(df_sub[\"feat\"], categories=order, ordered=True)\n",
    "\n",
    "        # Plot each dataset\n",
    "        sns.pointplot(\n",
    "            data=df_sub.sort_values(by=\"dataset\", ascending=False),\n",
    "            x=metric,\n",
    "            y=\"feat\",\n",
    "            hue=\"dataset\",\n",
    "            dodge=True,\n",
    "            errorbar=(\"sd\", 1),\n",
    "            capsize=0.25,\n",
    "            ax=ax,\n",
    "            linestyle=\"\",\n",
    "            palette=palette,\n",
    "            legend=True,\n",
    "            markersize=3,\n",
    "            err_kws={\"linewidth\": 1, \"alpha\": 0.5},\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{subtype}\")\n",
    "        ax.set_xlabel({\n",
    "            \"spearmanr\": \"Spearman correlation\",\n",
    "            \"abs_spearmanr\": \"Abs. Spearman correlation\",\n",
    "            \"pearsonr\": \"Pearson correlation\",\n",
    "            \"abs_pearsonr\": \"Abs. Pearson correlation\",\n",
    "            \"auroc\": \"AUROC\",\n",
    "        }.get(metric, metric))\n",
    "        ax.axvline(0, color='grey', lw=0.5)\n",
    "        ax.grid(True, axis=\"x\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.tick_params(axis='y', labelsize=10)\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "    # Remove legends from individual axes\n",
    "    for ax in axes:\n",
    "        ax.legend_.remove()\n",
    "\n",
    "    # Create a global legend from the first plot\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc=\"lower center\",        # or 'upper center', 'right', etc.\n",
    "        ncol=len(labels),          # horizontal layout\n",
    "        frameon=False,\n",
    "        fontsize=10,\n",
    "        bbox_to_anchor=(0.5, 0.97)  # (x, y) position relative to figure\n",
    "    )\n",
    "\n",
    "        #if ax != axes[0]:\n",
    "            #ax.set_yticklabels([])  # Only show y labels on first facet\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/{metric}_assocs_subtype_{rep_type}.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/{metric}_assocs_subtype_{rep_type}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import fisher_exact, mannwhitneyu\n",
    "from functools import partial\n",
    "\n",
    "def rep_renamer(x, constraints, prefix=\"z\"):\n",
    "    dim = int(x.split(\"_\")[1])\n",
    "    if dim < len(constraints):\n",
    "        return f\"{prefix}_{constraints[dim]}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "rep_type = \"icovae_MCL1_16\"\n",
    "target = \"RCB.score\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "model_type = \"ElasticNet\"\n",
    "\n",
    "def pbc_corr(x1, x2):\n",
    "    u_1 = len(np.unique(x1))\n",
    "    u_2 = len(np.unique(x2))\n",
    "\n",
    "    if min(u_1, u_2) == 2:\n",
    "        res = pointbiserialr(x1, x2)\n",
    "    else:\n",
    "        res = spearmanr(x1, x2)\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "class SigRes():\n",
    "    def __init__(self, statistic, pvalue):\n",
    "        self.statistic = statistic\n",
    "        self.pvalue = pvalue\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}/{experiment}/pico\"\n",
    "ext = \"_Size.at.diagnosis_18\"\n",
    "\n",
    "model_path = f\"{res_root}/{model_type}_{rep_type + ext}\"\n",
    "\n",
    "hue = None\n",
    "row = \"c_HER2.status\"\n",
    "col = \"c_ER.status\"\n",
    "\n",
    "\n",
    "def mwu_auc(x, y, x_rd, x_pcr, feat):\n",
    "    res = mannwhitneyu(x_rd[feat], x_pcr[feat])\n",
    "    auc = roc_auc_score(y, x[feat])\n",
    "    auc_neg = roc_auc_score(y, -1 * x[feat])\n",
    "    auc = np.max([auc, auc_neg])\n",
    "\n",
    "    return res, auc\n",
    "\n",
    "\n",
    "def fisher_auc(x, y, x_rd, x_pcr, feat):\n",
    "    cont_tab = pd.merge(\n",
    "        x_rd[feat].value_counts(),\n",
    "        x_pcr[feat].value_counts(),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"outer\",\n",
    "    ).fillna(0)\n",
    "\n",
    "    auc = roc_auc_score(y, x[feat])\n",
    "    auc_neg = roc_auc_score(y, -1 * x[feat])\n",
    "    auc = np.max([auc, auc_neg])\n",
    "\n",
    "    try:\n",
    "        res = fisher_exact(cont_tab)\n",
    "        res = SigRes(res[0], res[1])\n",
    "    except:\n",
    "        res = SigRes(1.0, 1.0)\n",
    "        #print(f\"{feat}, {auc}\")\n",
    "\n",
    "    return res, auc\n",
    "\n",
    "\n",
    "pcr_assocs = []\n",
    "for seed in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "    # LOAD ARGUMENTS\n",
    "    with open(f\"{model_path}/args_best_s{seed}.txt\", \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    constraints = args[\"constraints\"]\n",
    "    n_constraints = len(constraints)\n",
    "    confounders = args[\"confounders\"]\n",
    "    if confounders is None:\n",
    "        n_confounders = 0\n",
    "    else:\n",
    "        n_confounders = len(confounders)\n",
    "\n",
    "    # Load predictions\n",
    "    test_z = pd.read_csv(f\"{model_path}/z_pred_test_s{seed}.csv\")\n",
    "    train_z = pd.read_csv(f\"{model_path}/z_pred_train_s{seed}.csv\")\n",
    "\n",
    "    # Rename test df\n",
    "    test_z_rep_z = test_z.iloc[:, test_z.columns.str.startswith(\"z\")]\n",
    "    test_z_rep_c =  test_z.iloc[:, test_z.columns.str.startswith(\"c\")]\n",
    "    test_z_rep_y = test_z[[\"y\"]]\n",
    "    test_z_rep_z = test_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    test_z_rep_c = test_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    test_z_rep_y = test_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    test_z_rep = pd.concat([test_z_rep_z, test_z_rep_c, test_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    # Rename train df\n",
    "    train_z_rep_z = train_z.iloc[:, train_z.columns.str.startswith(\"z\")]\n",
    "    train_z_rep_c =  train_z.iloc[:, train_z.columns.str.startswith(\"c\")]\n",
    "    train_z_rep_y = train_z[[\"y\"]]\n",
    "    train_z_rep_z = train_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    train_z_rep_c = train_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "    train_z_rep_y = train_z_rep_y.rename({\"y\": target}, axis=1)\n",
    "\n",
    "    train_z_rep = pd.concat([train_z_rep_z, train_z_rep_c, train_z_rep_y], axis=1).dropna(axis=0)\n",
    "\n",
    "    for i, df in enumerate([train_z_rep, test_z_rep]):\n",
    "        x_00_pcr = df.loc[(df[target] == 1) & (df[col] < 0) & (df[row] < 0)]\n",
    "        x_10_pcr = df.loc[(df[target] == 1) & (df[col] > 0) & (df[row] > 0)]\n",
    "        x_01_pcr = df.loc[(df[target] == 1) & (df[col] < 0) & (df[row] > 0)]\n",
    "        x_11_pcr = df.loc[(df[target] == 1) & (df[col] > 0) & (df[row] > 0)]\n",
    "        x_00_rd = df.loc[(df[target] == 0) & (df[col] < 0) & (df[row] < 0)]\n",
    "        x_10_rd = df.loc[(df[target] == 0) & (df[col] > 0) & (df[row] < 0)]\n",
    "        x_01_rd = df.loc[(df[target] == 0) & (df[col] < 0) & (df[row] > 0)]\n",
    "        x_11_rd = df.loc[(df[target] == 0) & (df[col] > 0) & (df[row] > 0)]\n",
    "\n",
    "        x_00 = df.loc[(df[col] < 0) & (df[row] < 0)]\n",
    "        x_01 = df.loc[(df[col] < 0) & (df[row] > 0)]\n",
    "        x_10 = df.loc[(df[col] > 0) & (df[row] < 0)]\n",
    "        x_11 = df.loc[(df[col] > 0) & (df[row] > 0)]\n",
    "\n",
    "        y_00 = x_00[target]\n",
    "        y_01 = x_01[target]\n",
    "        y_10 = x_10[target]\n",
    "        y_11 = x_11[target]\n",
    "\n",
    "        if i == 0:\n",
    "            dataset = \"TransNEO\"\n",
    "        else:\n",
    "            dataset = \"ARTemis+PBCP\"\n",
    "\n",
    "        for feat in df.columns:\n",
    "            if feat != target:\n",
    "                # Check if continuous else use Fisher's exact test\n",
    "                if len(df[feat].unique()) > 2:\n",
    "                    res_00, auc_00 = mwu_auc(x_00, y_00, x_00_rd, x_00_pcr, feat)\n",
    "                    res_01, auc_01 = mwu_auc(x_01, y_01, x_01_rd, x_01_pcr, feat)\n",
    "                    res_10, auc_10 = mwu_auc(x_10, y_10, x_10_rd, x_10_pcr, feat)\n",
    "                    res_11, auc_11 = mwu_auc(x_11, y_11, x_11_rd, x_11_pcr, feat)\n",
    "                else:\n",
    "                    # print(np.stack((x_0_0_rd[feat].value_counts().to_numpy(), x_0_0_pcr[feat].value_counts().to_numpy()), axis=1))\n",
    "                    res_00, auc_00 = fisher_auc(x_00, y_00, x_00_rd, x_00_pcr, feat)\n",
    "                    res_01, auc_01 = fisher_auc(x_01, y_01, x_01_rd, x_01_pcr, feat)\n",
    "                    res_10, auc_10 = fisher_auc(x_10, y_10, x_10_rd, x_10_pcr, feat)\n",
    "                    res_11, auc_11 = fisher_auc(x_11, y_11, x_11_rd, x_11_pcr, feat)\n",
    "\n",
    "                pcr_assocs.append(\n",
    "                    {\n",
    "                        \"feat\": feat,\n",
    "                        \"group\": \"ER-HER2-\",\n",
    "                        \"p\": res_00.pvalue,\n",
    "                        \"auc\": auc_00,\n",
    "                        \"seed\": seed,\n",
    "                        \"dataset\": dataset,\n",
    "                    }\n",
    "                )\n",
    "                pcr_assocs.append(\n",
    "                    {\n",
    "                        \"feat\": feat,\n",
    "                        \"group\": \"ER+HER2-\",\n",
    "                        \"p\": res_10.pvalue,\n",
    "                        \"auc\": auc_10,\n",
    "                        \"seed\": seed,\n",
    "                        \"dataset\": dataset,\n",
    "                    }\n",
    "                )\n",
    "                pcr_assocs.append(\n",
    "                    {\n",
    "                        \"feat\": feat,\n",
    "                        \"group\": \"ER-HER2+\",\n",
    "                        \"p\": res_01.pvalue,\n",
    "                        \"auc\": auc_01,\n",
    "                        \"seed\": seed,\n",
    "                        \"dataset\": dataset,\n",
    "                    }\n",
    "                )\n",
    "                pcr_assocs.append(\n",
    "                    {\n",
    "                        \"feat\": feat,\n",
    "                        \"group\": \"ER+HER2+\",\n",
    "                        \"p\": res_11.pvalue,\n",
    "                        \"auc\": auc_11,\n",
    "                        \"seed\": seed,\n",
    "                        \"dataset\": dataset,\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING\n",
    "## DO AUPR, DO ALL SAMPLES\n",
    "n_feats = 20\n",
    "\n",
    "pcr_assocs_df = pd.DataFrame(pcr_assocs)\n",
    "pcr_assocs_df[\"logp\"] = np.log(pcr_assocs_df[\"p\"])\n",
    "\n",
    "pcr_assocs_df[\"feat\"] = pcr_assocs_df[\"feat\"].apply(lambda x: x.split(\"_\"))\n",
    "pcr_assocs_df[\"feat\"] = pcr_assocs_df[\"feat\"].apply(\n",
    "    lambda x: rf\"$z_{{{x[1]}}}$\" if x[0] == \"z\" else names_map[x[1]]\n",
    ")\n",
    "\n",
    "pcr_assocs_df_mean = (\n",
    "    pcr_assocs_df[pcr_assocs_df[\"dataset\"] == \"TransNEO\"]\n",
    "    .groupby([\"feat\", \"group\", \"dataset\"])\n",
    "    .mean()\n",
    "    .sort_values(by=\"auc\", ascending=False)\n",
    "    .groupby([\"group\", \"dataset\"])\n",
    "    .head(n_feats)\n",
    "    .reset_index()\n",
    "    .set_index([\"feat\", \"group\"])\n",
    ")\n",
    "# print(pcr_assocs_df_mean)\n",
    "\n",
    "# if row == \"c_HER2.status\":\n",
    "#     col_order = [\"HER2-\", \"HER2+\"]\n",
    "# elif row == \"c_ER.status\":\n",
    "#     col_order = [\"ER-\", \"ER+\"]\n",
    "\n",
    "# pcr_assocs_df_plot = pcr_assocs_df.set_index([\"feat\", \"group\"]).loc[pcr_assocs_df_mean.index].reset_index()\n",
    "\n",
    "pcr_assocs_df_hm = (\n",
    "    pcr_assocs_df.set_index([\"feat\", \"group\"])\n",
    "    .loc[pcr_assocs_df_mean.index]\n",
    "    .reset_index()\n",
    "    .pivot_table(index=[\"dataset\", \"group\"], columns=\"feat\", values=\"auc\")\n",
    ")\n",
    "\n",
    "g1 = sns.catplot(\n",
    "    data=pcr_assocs_df.set_index([\"feat\", \"group\"])\n",
    "    .loc[pcr_assocs_df_mean.index]\n",
    "    .reset_index(),\n",
    "    height=n_feats / 5.5,\n",
    "    aspect=0.8,\n",
    "    kind=\"point\",\n",
    "    col=\"group\",\n",
    "    #col_order=col_order,\n",
    "    sharey=False,\n",
    "    sharex=True,\n",
    "    x=\"auc\",\n",
    "    y=\"feat\",\n",
    "    hue=\"dataset\",\n",
    "    errorbar=(\"sd\", 1),\n",
    "    capsize=0.25,\n",
    "    linestyle=\"none\",\n",
    "    markersize=3,\n",
    "    err_kws={\"linewidth\": 1, \"alpha\": 0.5},\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "axes = g1.axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    # ax.invert_xaxis()\n",
    "    ax.set_title(col_order[i], fontweight=\"semibold\")\n",
    "    ax.set_xlabel(\"AUROC\")\n",
    "    ax.set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.grid(visible=True, axis=\"x\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylabel(\"\")\n",
    "sns.despine()\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "leg1 = axes[0].legend(\n",
    "    handles=handles,\n",
    "    bbox_to_anchor=(1.3, 1.2),\n",
    "    loc=\"upper center\",\n",
    "    frameon=False,\n",
    "    ncol=2,\n",
    ")\n",
    "axes[0].add_artist(leg1)\n",
    "g1._legend.remove()\n",
    "axes[0].set_yticklabels(axes[0].get_ymajorticklabels(), fontsize=10)\n",
    "axes[1].set_yticklabels(axes[1].get_ymajorticklabels(), fontsize=10)\n",
    "\n",
    "plt.savefig(\n",
    "    f\"./ext_val_sammut/figures/pcr_assocs_{rep_type}_{row}_{n_feats}.svg\",\n",
    "    bbox_inches=\"tight\",\n",
    "    bbox_extra_artists=(leg1,),\n",
    ")\n",
    "plt.savefig(\n",
    "    f\"./ext_val_sammut/figures/pcr_assocs_{rep_type}_{row}_{n_feats}.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    bbox_extra_artists=(leg1,),\n",
    "    dpi=600,\n",
    ")\n",
    "\n",
    "# print(pcr_assocs_df_hm)\n",
    "\n",
    "# f, ax = plt.subplots(1,2, figsize=(5,5), sharey=False)\n",
    "# sns.heatmap(pcr_assocs_df_hm.loc(axis=0)[:, \"HER2-\"].transpose().dropna(axis=0), square=True, cmap=\"Blues\", yticklabels=True, xticklabels=True, ax=ax[0], vmin=0, vmax=1)\n",
    "# sns.heatmap(pcr_assocs_df_hm.loc(axis=0)[:, \"HER2+\"].transpose().dropna(axis=0), square=True, cmap=\"Blues\", yticklabels=True, xticklabels=True, ax=ax[1], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results for reporting\n",
    "pcr_assocs_df.groupby([\"feat\", \"group\", \"dataset\"]).mean().sort_values(\n",
    "    \"auc\", ascending=False\n",
    ").head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Representation UMAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## SCATTER PLOT FEATURES\n",
    "from scipy.stats import pointbiserialr, spearmanr\n",
    "from functools import partial\n",
    "\n",
    "def rep_renamer(x, constraints, prefix=\"z\"):\n",
    "    dim = int(x.split(\"_\")[1])\n",
    "    if dim < len(constraints):\n",
    "        return f\"{prefix}_{constraints[dim]}\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "rep_type = \"icovae_MCL1_16\"\n",
    "#rep_type = \"vae\"\n",
    "target = \"RCB.score\"\n",
    "experiment = \"artemis_pbcp\"\n",
    "model_type = \"ElasticNet\"\n",
    "\n",
    "def pbc_corr(x1, x2):\n",
    "    u_1 = len(np.unique(x1))\n",
    "    u_2 = len(np.unique(x2))\n",
    "\n",
    "    if min(u_1, u_2) == 2:\n",
    "        res = pointbiserialr(x1, x2)\n",
    "    else:\n",
    "        res = spearmanr(x1, x2)\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "def plot_umap(x, hue, n_neighbors=20, seed=10):\n",
    "\n",
    "    pal = sns.color_palette(\"colorblind\")\n",
    "\n",
    "    # merge dfs\n",
    "    if hue in [\"TP53\", \"PIK3CA\", \"PTEN\"]:\n",
    "        palette = {1.0: pal[0], 0.0: pal[1], \"NA\": \"lightgrey\"}\n",
    "    elif hue.startswith((\"z_\", \"GGI\", \"STAT1\", \"All.TMB\", \"Coding.TMB\", \"c_GGI\")):\n",
    "        palette = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "    elif hue == \"PAM50\":\n",
    "        palette = {\n",
    "            \"Basal\": pal[0],\n",
    "            \"LumA\": pal[1],\n",
    "            \"LumB\": pal[2],\n",
    "            \"Her2\": pal[3],\n",
    "            \"Normal\": pal[4],\n",
    "            \"NA\": \"lightgrey\",\n",
    "        }\n",
    "    elif hue == \"c_MolType\":\n",
    "        palette = {\n",
    "            \"ER+/HER2-\": pal[0],\n",
    "            \"ER+/HER2+\": pal[1],\n",
    "            \"ER-/HER2+\": pal[2],\n",
    "            \"ER-/HER2-\": pal[3],\n",
    "            \"NA\": \"lightgrey\",\n",
    "        }\n",
    "    else:\n",
    "        palette = pal\n",
    "\n",
    "    n_samp = len(x)\n",
    "    print(f\"n: {n_samp}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "    surv_rep_zs = x.loc[:, x.columns.str.startswith(\"z_\")]\n",
    "\n",
    "    # standardize z dimensions for t-SNE\n",
    "    scaler = StandardScaler()\n",
    "    surv_rep_zs = scaler.fit_transform(surv_rep_zs)\n",
    "\n",
    "    results_tsne_df = UMAP(\n",
    "        n_components=2, n_neighbors=n_neighbors, min_dist=0.01, random_state=seed,\n",
    "    ).fit_transform(surv_rep_zs)\n",
    "\n",
    "    results_tsne_df = pd.DataFrame(results_tsne_df).rename(\n",
    "        {0: \"UMAP1\", 1: \"UMAP2\"}, axis=1\n",
    "    )\n",
    "    results_tsne_df.index = x.index\n",
    "\n",
    "    results_tsne_df = pd.merge(results_tsne_df, x, left_index=True, right_index=True)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=results_tsne_df,\n",
    "        x=\"UMAP1\",\n",
    "        y=\"UMAP2\",\n",
    "        hue=hue,\n",
    "        style=\"dataset\",\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        s=30,\n",
    "    )\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    sns.despine(bottom=True, top=True, left=True, right=True)\n",
    "\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    #h, l = zip(*sorted(zip(h, l), key=lambda t: t[1]))\n",
    "    h[5].text = \"Dataset\"\n",
    "    h = h[1:]\n",
    "    l = l[1:]\n",
    "\n",
    "    for handle in h:\n",
    "        handle.set_markersize(6.0)\n",
    "    hue_map = {\n",
    "        \"c_PAM50\": \"PAM50 subtype\",\n",
    "        \"c_NCN.PAM50\": \"PAM50 subtype\",\n",
    "        \"c_ClinGroup\": \"Clinical subgroup\",\n",
    "        \"TP53\": \"TP53 mutation status\",\n",
    "        \"PIK3CA\": \"PIK3CA mutation status\",\n",
    "        \"c_GGI.ssgsea.notnorm\": \"GGI score\",\n",
    "        \"c_ER.status\": \"ER status\",\n",
    "        \"c_HER2.status\": \"HER2 status\",\n",
    "        \"c_Histology\": \"Histology\",\n",
    "        \"c_MolType\": \"Molecular subtype\",\n",
    "        \"dataset\": \"Dataset\",\n",
    "    }\n",
    "    ax.legend(\n",
    "        handles=h,\n",
    "        labels=l,\n",
    "        title=hue_map[hue],\n",
    "        fontsize=\"medium\",\n",
    "        ncol=1,\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(1.20, 1.15),\n",
    "        loc=\"upper center\",\n",
    "        title_fontproperties={\"style\": \"italic\", \"size\": \"medium\"},\n",
    "    )\n",
    "\n",
    "    # plt.legend('',frameon=False)\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/UMAP_{hue}_n{n_neighbors}_s{seed}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "    )\n",
    "    plt.savefig(\n",
    "        f\"./figures/transneo/UMAP_{hue}_n{n_neighbors}_s{seed}.svg\", bbox_inches=\"tight\"\n",
    "    )\n",
    "\n",
    "res_root = f\"{wd_path}/data/outputs/depmap_gdsc_transneo/{target}/{experiment}/pico\"\n",
    "ext = \"_Size.at.diagnosis_18\"\n",
    "\n",
    "model_path = f\"{res_root}/{model_type}_{rep_type + ext}\"\n",
    "\n",
    "corrs = []\n",
    "corrs_val = []\n",
    "for seed in [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "\n",
    "    # LOAD ARGUMENTS\n",
    "    with open(f\"{model_path}/args_best_s{seed}.txt\", \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    constraints = args[\"constraints\"]\n",
    "    n_constraints = len(constraints)\n",
    "    confounders = args[\"confounders\"]\n",
    "    if confounders is None:\n",
    "        n_confounders = 0\n",
    "    else:\n",
    "        n_confounders = len(confounders)\n",
    "\n",
    "    # Load predictions\n",
    "    test_z = pd.read_csv(f\"{model_path}/z_pred_test_s{seed}.csv\")\n",
    "    train_z = pd.read_csv(f\"{model_path}/z_pred_train_s{seed}.csv\")\n",
    "\n",
    "    # Rename test df\n",
    "    test_z_rep_z = test_z.iloc[:, test_z.columns.str.startswith(\"z\")]\n",
    "    test_z_rep_c =  test_z.iloc[:, test_z.columns.str.startswith(\"c\")]\n",
    "    test_z_rep_z = test_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    test_z_rep_c = test_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "\n",
    "    test_z_rep = pd.concat([test_z_rep_z, test_z_rep_c], axis=1)\n",
    "\n",
    "    # Rename train df\n",
    "    train_z_rep_z = train_z.iloc[:, train_z.columns.str.startswith(\"z\")]\n",
    "    train_z_rep_c =  train_z.iloc[:, train_z.columns.str.startswith(\"c\")]\n",
    "    train_z_rep_z = train_z_rep_z.rename(\n",
    "        mapper=partial(rep_renamer, constraints=constraints, prefix=\"z\"), axis=1\n",
    "    )\n",
    "    train_z_rep_c = train_z_rep_c.rename(\n",
    "        mapper=partial(rep_renamer, constraints=confounders, prefix=\"c\"), axis=1\n",
    "    )\n",
    "\n",
    "    train_z_rep = pd.concat([train_z_rep_z, train_z_rep_c], axis=1)\n",
    "\n",
    "    # Concatenate train and test\n",
    "    test_z_rep[\"dataset\"] = \"Artemis+PBCP\"\n",
    "    train_z_rep[\"dataset\"] = \"TransNEO\"\n",
    "    train_z_rep = pd.concat([train_z_rep, test_z_rep], axis=0).reset_index()\n",
    "\n",
    "    train_z_rep[\"c_ER.status\"] = train_z_rep[\"c_ER.status\"] > 0 \n",
    "    train_z_rep[\"c_HER2.status\"] = train_z_rep[\"c_HER2.status\"] > 0 \n",
    "    train_z_rep[\"c_MolType\"] = train_z_rep[\"c_ER.status\"].astype(str) + train_z_rep[\"c_HER2.status\"].astype(str)\n",
    "\n",
    "    moltype_map = {\"TrueFalse\": \"ER+/HER2-\", \"TrueTrue\": \"ER+/HER2+\", \"FalseTrue\": \"ER-/HER2+\", \"FalseFalse\": \"ER-/HER2-\"}\n",
    "\n",
    "    train_z_rep[\"c_MolType\"] = train_z_rep[\"c_MolType\"].apply(lambda x: moltype_map[x])\n",
    "\n",
    "\n",
    "    plot_umap(train_z_rep, hue=\"c_MolType\", n_neighbors=15, seed=seed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
